# SenseVoice
# ç”¨æ³• ğŸ› ï¸

## æ¨ç†

### ä½¿ç”¨ funasr æ¨ç†

æ”¯æŒä»»æ„æ ¼å¼éŸ³é¢‘è¾“å…¥ï¼Œæ”¯æŒä»»æ„æ—¶é•¿è¾“å…¥

```python
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess

model_dir = "iic/SenseVoiceSmall"


model = AutoModel(
    model=model_dir,
    trust_remote_code=True,
    remote_code="./model.py",  
    vad_model="fsmn-vad",
    vad_kwargs={"max_single_segment_time": 30000},
    device="cuda:0",
)

res = model.generate(
    input=f"{model.model_path}/example/en.mp3",
    cache={},
    language="auto",  # "zh", "en", "yue", "ja", "ko", "nospeech"
    use_itn=True,
    batch_size_s=60,
    merge_vad=True,
    merge_length_s=15,
)
text = rich_transcription_postprocess(res[0]["text"])
print(text)
```

<details><summary> å‚æ•°è¯´æ˜ï¼ˆç‚¹å‡»å±•å¼€ï¼‰</summary>

- `model_dir`ï¼šæ¨¡å‹åç§°ï¼Œæˆ–æœ¬åœ°ç£ç›˜ä¸­çš„æ¨¡å‹è·¯å¾„ã€‚
- `trust_remote_code`ï¼š
  - `True` è¡¨ç¤º model ä»£ç å®ç°ä» `remote_code` å¤„åŠ è½½ï¼Œ`remote_code` æŒ‡å®š `model` å…·ä½“ä»£ç çš„ä½ç½®ï¼ˆä¾‹å¦‚ï¼Œå½“å‰ç›®å½•ä¸‹çš„ `model.py`ï¼‰ï¼Œæ”¯æŒç»å¯¹è·¯å¾„ä¸ç›¸å¯¹è·¯å¾„ï¼Œä»¥åŠç½‘ç»œ urlã€‚
  - `False` è¡¨ç¤ºï¼Œmodel ä»£ç å®ç°ä¸º [FunASR](https://github.com/modelscope/FunASR) å†…éƒ¨é›†æˆç‰ˆæœ¬ï¼Œæ­¤æ—¶ä¿®æ”¹å½“å‰ç›®å½•ä¸‹çš„ `model.py` ä¸ä¼šç”Ÿæ•ˆï¼Œå› ä¸ºåŠ è½½çš„æ˜¯ funasr å†…éƒ¨ç‰ˆæœ¬ï¼Œæ¨¡å‹ä»£ç  [ç‚¹å‡»æŸ¥çœ‹](https://github.com/modelscope/FunASR/tree/main/funasr/models/sense_voice)ã€‚
- `vad_model`ï¼šè¡¨ç¤ºå¼€å¯ VADï¼ŒVAD çš„ä½œç”¨æ˜¯å°†é•¿éŸ³é¢‘åˆ‡å‰²æˆçŸ­éŸ³é¢‘ï¼Œæ­¤æ—¶æ¨ç†è€—æ—¶åŒ…æ‹¬äº† VAD ä¸ SenseVoice æ€»è€—æ—¶ï¼Œä¸ºé“¾è·¯è€—æ—¶ï¼Œå¦‚æœéœ€è¦å•ç‹¬æµ‹è¯• SenseVoice æ¨¡å‹è€—æ—¶ï¼Œå¯ä»¥å…³é—­ VAD æ¨¡å‹ã€‚
- `vad_kwargs`ï¼šè¡¨ç¤º VAD æ¨¡å‹é…ç½®ï¼Œ`max_single_segment_time`: è¡¨ç¤º `vad_model` æœ€å¤§åˆ‡å‰²éŸ³é¢‘æ—¶é•¿ï¼Œå•ä½æ˜¯æ¯«ç§’ msã€‚
- `use_itn`ï¼šè¾“å‡ºç»“æœä¸­æ˜¯å¦åŒ…å«æ ‡ç‚¹ä¸é€†æ–‡æœ¬æ­£åˆ™åŒ–ã€‚
- `batch_size_s` è¡¨ç¤ºé‡‡ç”¨åŠ¨æ€ batchï¼Œbatch ä¸­æ€»éŸ³é¢‘æ—¶é•¿ï¼Œå•ä½ä¸ºç§’ sã€‚
- `merge_vad`ï¼šæ˜¯å¦å°† vad æ¨¡å‹åˆ‡å‰²çš„çŸ­éŸ³é¢‘ç¢ç‰‡åˆæˆï¼Œåˆå¹¶åé•¿åº¦ä¸º `merge_length_s`ï¼Œå•ä½ä¸ºç§’ sã€‚
- `ban_emo_unk`ï¼šç¦ç”¨ emo_unk æ ‡ç­¾ï¼Œç¦ç”¨åæ‰€æœ‰çš„å¥å­éƒ½ä¼šè¢«èµ‹ä¸æƒ…æ„Ÿæ ‡ç­¾ã€‚é»˜è®¤ `False`

</details>

å¦‚æœè¾“å…¥å‡ä¸ºçŸ­éŸ³é¢‘ï¼ˆå°äº 30sï¼‰ï¼Œå¹¶ä¸”éœ€è¦æ‰¹é‡åŒ–æ¨ç†ï¼Œä¸ºäº†åŠ å¿«æ¨ç†æ•ˆç‡ï¼Œå¯ä»¥ç§»é™¤ vad æ¨¡å‹ï¼Œå¹¶è®¾ç½® `batch_size`

```python
model = AutoModel(model=model_dir, trust_remote_code=True, device="cuda:0")

res = model.generate(
    input=f"{model.model_path}/example/en.mp3",
    cache={},
    language="auto", # "zh", "en", "yue", "ja", "ko", "nospeech"
    use_itn=True,
    batch_size=64, 
)
```

æ›´å¤šè¯¦ç»†ç”¨æ³•ï¼Œè¯·å‚è€ƒ [æ–‡æ¡£](https://github.com/modelscope/FunASR/blob/main/docs/tutorial/README.md)

### ç›´æ¥æ¨ç†

æ”¯æŒä»»æ„æ ¼å¼éŸ³é¢‘è¾“å…¥ï¼Œè¾“å…¥éŸ³é¢‘æ—¶é•¿é™åˆ¶åœ¨ 30s ä»¥ä¸‹

```python
from model import SenseVoiceSmall
from funasr.utils.postprocess_utils import rich_transcription_postprocess

model_dir = "iic/SenseVoiceSmall"
m, kwargs = SenseVoiceSmall.from_pretrained(model=model_dir, device="cuda:0")
m.eval()

res = m.inference(
    data_in=f"{kwargs ['model_path']}/example/en.mp3",
    language="auto", # "zh", "en", "yue", "ja", "ko", "nospeech"
    use_itn=False,
    ban_emo_unk=False,
    **kwargs,
)

text = rich_transcription_postprocess(res [0][0]["text"])
print(text)
```
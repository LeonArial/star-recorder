"""
å®æ—¶è¯­éŸ³è¯†åˆ«æœåŠ¡å™¨
æ”¯æŒ WebSocket å®æ—¶ä¼ è¾“éŸ³é¢‘æ•°æ®å¹¶è¿”å›è¯†åˆ«ç»“æœ
"""
import asyncio
import json
import numpy as np
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit
from funasr import AutoModel
import threading
import queue
import time

app = Flask(__name__)
app.config['SECRET_KEY'] = 'sensevoice-realtime-asr'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# å…¨å±€æ¨¡å‹å®ä¾‹
asr_model = None
vad_model = None
punc_model = None

# æ¨¡å‹åŠ è½½é”
model_lock = threading.Lock()

def init_models():
    """åˆå§‹åŒ– ASRã€VADã€æ ‡ç‚¹æ¨¡å‹"""
    global asr_model, vad_model, punc_model
    
    with model_lock:
        if asr_model is None:
            print("ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹...")
            
            # åŠ è½½ä¸­æ–‡æµå¼ ASR æ¨¡å‹
            print("  - åŠ è½½ ASR æ¨¡å‹: paraformer-zh-streaming")
            asr_model = AutoModel(
                model="paraformer-zh-streaming",
                device="cuda:0",  # æ”¹ä¸º "cuda:0" ä½¿ç”¨ GPU
                disable_update=True,
            )
            
            # åŠ è½½ VAD æ¨¡å‹ï¼ˆè¯­éŸ³ç«¯ç‚¹æ£€æµ‹ï¼‰
            print("  - åŠ è½½ VAD æ¨¡å‹: fsmn-vad")
            vad_model = AutoModel(
                model="fsmn-vad",
                device="cuda:0",
                disable_update=True,
            )
            
            # åŠ è½½æ ‡ç‚¹æ¢å¤æ¨¡å‹
            print("  - åŠ è½½æ ‡ç‚¹æ¨¡å‹: ct-punc")
            punc_model = AutoModel(
                model="ct-punc",
                device="cuda:0",
                disable_update=True,
            )
            
            print("âœ… æ‰€æœ‰æ¨¡å‹åŠ è½½å®Œæˆï¼")

class RealtimeASR:
    """å®æ—¶è¯­éŸ³è¯†åˆ«å¤„ç†å™¨"""
    
    def __init__(self, session_id):
        self.session_id = session_id
        self.audio_buffer = []
        self.sample_rate = 16000
        self.is_processing = False
        self.last_result = ""
        self.cache = {}  # æµå¼è¯†åˆ«ç¼“å­˜
        self.chunk_size = [0, 10, 5]  # [0, 10, 5] è¡¨ç¤º600mså®æ—¶å‡ºå­—ï¼Œ300msæœªæ¥ä¿¡æ¯
        self.chunk_stride = self.chunk_size[1] * 960  # 600mså¯¹åº”çš„é‡‡æ ·ç‚¹æ•°
        self.all_text = ""  # ç´¯ç§¯æ‰€æœ‰è¯†åˆ«æ–‡æœ¬ï¼ˆæ— æ ‡ç‚¹ï¼‰
        self.text_with_punc = ""  # å·²æ·»åŠ æ ‡ç‚¹çš„æ–‡æœ¬
        self.pending_text = ""  # ç­‰å¾…æ ‡ç‚¹çš„æ–‡æœ¬
        self.punc_threshold = 30  # ç´¯ç§¯åˆ°30å­—ç¬¦æ—¶åšæ ‡ç‚¹
        
    def add_audio(self, audio_data):
        """æ·»åŠ éŸ³é¢‘æ•°æ®åˆ°ç¼“å†²åŒº"""
        try:
            # ç¡®ä¿æ•°æ®é•¿åº¦æ˜¯ 2 çš„å€æ•°ï¼ˆint16 = 2 bytesï¼‰
            if len(audio_data) % 2 != 0:
                # å¦‚æœä¸æ˜¯å¶æ•°ï¼Œæˆªæ–­æœ€åä¸€ä¸ªå­—èŠ‚
                audio_data = audio_data[:-1]
            
            if len(audio_data) == 0:
                return
            
            # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸º float32 numpy æ•°ç»„
            audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0
            self.audio_buffer.extend(audio_np)
        except Exception as e:
            print(f"âŒ éŸ³é¢‘æ•°æ®å¤„ç†é”™è¯¯: {e}, æ•°æ®é•¿åº¦: {len(audio_data)}")
        
    def process_audio(self):
        """å¤„ç†ç¼“å†²åŒºä¸­çš„éŸ³é¢‘ï¼ˆæµå¼ï¼‰"""
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„éŸ³é¢‘æ•°æ®ï¼ˆ600msï¼‰
        if len(self.audio_buffer) < self.chunk_stride:
            return None
        
        try:
            # å–å‡ºä¸€ä¸ª chunk çš„éŸ³é¢‘
            speech_chunk = np.array(self.audio_buffer[:self.chunk_stride], dtype=np.float32)
            
            # æµå¼ ASR è¯†åˆ«
            asr_result = asr_model.generate(
                input=speech_chunk,
                cache=self.cache,
                is_final=False,
                chunk_size=self.chunk_size,
                encoder_chunk_look_back=4,
                decoder_chunk_look_back=1,
            )
            
            if asr_result and len(asr_result) > 0:
                text = asr_result[0]["text"]
                
                # ç´¯ç§¯åŸå§‹æ–‡æœ¬
                self.all_text += text
                self.pending_text += text
                
                # ç§»é™¤å·²å¤„ç†çš„éŸ³é¢‘
                self.audio_buffer = self.audio_buffer[self.chunk_stride:]
                
                # å¢é‡æ ‡ç‚¹æ¢å¤ï¼ˆç´¯ç§¯åˆ°é˜ˆå€¼æ—¶å¤„ç†ï¼‰
                punc_text = ""
                if len(self.pending_text) >= self.punc_threshold and punc_model:
                    try:
                        # å¯¹å¾…å¤„ç†æ–‡æœ¬åšæ ‡ç‚¹
                        punc_result = punc_model.generate(input=self.pending_text)
                        if punc_result and len(punc_result) > 0:
                            punc_text = punc_result[0]["text"]
                            
                            # ä¿ç•™æœ€å10ä¸ªå­—ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œé¿å…æ–­å¥ä¸è¿è´¯
                            if len(self.pending_text) > 10:
                                # å·²ç¡®è®¤çš„å¸¦æ ‡ç‚¹æ–‡æœ¬
                                confirmed = punc_text[:-10] if len(punc_text) > 10 else ""
                                self.text_with_punc += confirmed
                                
                                # å‰©ä½™éƒ¨åˆ†ç»§ç»­ç­‰å¾…
                                self.pending_text = self.pending_text[-10:]
                            else:
                                self.text_with_punc += punc_text
                                self.pending_text = ""
                    except Exception as e:
                        print(f"âš ï¸ å¢é‡æ ‡ç‚¹å¤±è´¥: {e}")
                
                # è¿”å›å¢é‡ç»“æœ
                return {
                    "text": text,  # åŸå§‹æ–°å¢æ–‡æœ¬
                    "full_text_with_punc": self.text_with_punc + self.pending_text,  # å®Œæ•´å¸¦æ ‡ç‚¹æ–‡æœ¬
                    "is_final": False,
                }
        except Exception as e:
            print(f"âŒ è¯†åˆ«é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            
        return None
    
    def finalize(self):
        """å¤„ç†å‰©ä½™çš„éŸ³é¢‘å¹¶è¿”å›æœ€ç»ˆç»“æœ"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å‰©ä½™éŸ³é¢‘æˆ–ç¼“å­˜å†…å®¹
            if len(self.audio_buffer) > 0:
                # æœ‰å‰©ä½™éŸ³é¢‘ï¼šå¤„ç†å‰©ä½™éŸ³é¢‘
                speech_chunk = np.array(self.audio_buffer, dtype=np.float32)
                
                # æœ€åä¸€ä¸ªchunkï¼Œè®¾ç½® is_final=True å¼ºåˆ¶è¾“å‡ºç¼“å­˜
                asr_result = asr_model.generate(
                    input=speech_chunk,
                    cache=self.cache,
                    is_final=True,  # å¼ºåˆ¶è¾“å‡ºæœ€åä¸€ä¸ªå­—
                    chunk_size=self.chunk_size,
                    encoder_chunk_look_back=4,
                    decoder_chunk_look_back=1,
                )
            elif self.cache:
                # æ²¡æœ‰å‰©ä½™éŸ³é¢‘ä½†æœ‰ç¼“å­˜ï¼šå‘é€ä¸€ä¸ªå®Œæ•´çš„é™éŸ³chunk
                speech_chunk = np.zeros(self.chunk_stride, dtype=np.float32)  # 600ms é™éŸ³
                
                asr_result = asr_model.generate(
                    input=speech_chunk,
                    cache=self.cache,
                    is_final=True,
                    chunk_size=self.chunk_size,
                    encoder_chunk_look_back=4,
                    decoder_chunk_look_back=1,
                )
            else:
                # æ—¢æ²¡æœ‰å‰©ä½™éŸ³é¢‘ä¹Ÿæ²¡æœ‰ç¼“å­˜ï¼šç›´æ¥è¿”å›å·²æœ‰æ–‡æœ¬
                asr_result = None
            
            if asr_result and len(asr_result) > 0:
                text = asr_result[0]["text"]
                if text:  # åªæœ‰éç©ºæ–‡æœ¬æ‰ç´¯ç§¯
                    self.all_text += text
                    self.pending_text += text
                    print(f"ğŸ“ æœ€ç»ˆè¯†åˆ«: {text}")
            
            # å¯¹å‰©ä½™å¾…å¤„ç†æ–‡æœ¬è¿›è¡Œæœ€ç»ˆæ ‡ç‚¹æ¢å¤
            if self.pending_text and punc_model:
                try:
                    punc_result = punc_model.generate(input=self.pending_text)
                    if punc_result and len(punc_result) > 0:
                        self.text_with_punc += punc_result[0]["text"]
                except Exception as e:
                    print(f"âš ï¸ æœ€ç»ˆæ ‡ç‚¹æ¢å¤å¤±è´¥: {e}")
                    self.text_with_punc += self.pending_text
            else:
                self.text_with_punc += self.pending_text
            
            final_text = self.text_with_punc
            
            print(f"âœ… å®Œæ•´æ–‡æœ¬: {final_text}")
            print(f"ğŸ“Š æ€»å­—æ•°: {len(final_text)}")
            
            # æ¸…ç©ºæ‰€æœ‰çŠ¶æ€
            self.audio_buffer = []
            self.cache = {}
            self.all_text = ""
            self.text_with_punc = ""
            self.pending_text = ""
            
            return {
                "text": final_text,
                "full_text_with_punc": final_text,
                "is_final": True,
            }
        except Exception as e:
            print(f"âŒ æœ€ç»ˆè¯†åˆ«é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            
            # å³ä½¿å‡ºé”™ï¼Œä¹Ÿè¿”å›å·²æœ‰çš„æ–‡æœ¬
            return {
                "text": self.text_with_punc + self.pending_text,
                "full_text_with_punc": self.text_with_punc + self.pending_text,
                "is_final": True,
            }

# å­˜å‚¨æ‰€æœ‰ä¼šè¯
sessions = {}

@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('realtime_asr.html')

@socketio.on('connect')
def handle_connect():
    """å®¢æˆ·ç«¯è¿æ¥"""
    sid = request.sid
    print(f"âœ… å®¢æˆ·ç«¯è¿æ¥: {sid}")
    
    # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
    if asr_model is None:
        init_models()
    
    # åˆ›å»ºæ–°ä¼šè¯
    sessions[sid] = RealtimeASR(sid)
    emit('connected', {'status': 'ready'})

@socketio.on('disconnect')
def handle_disconnect():
    """å®¢æˆ·ç«¯æ–­å¼€"""
    sid = request.sid
    print(f"âŒ å®¢æˆ·ç«¯æ–­å¼€: {sid}")
    if sid in sessions:
        del sessions[sid]

@socketio.on('start_recording')
def handle_start_recording():
    """å¼€å§‹å½•éŸ³"""
    sid = request.sid
    print(f"ğŸ™ï¸ å¼€å§‹å½•éŸ³: {sid}")
    if sid in sessions:
        sessions[sid].audio_buffer = []
        sessions[sid].cache = {}
        sessions[sid].all_text = ""
        sessions[sid].text_with_punc = ""
        sessions[sid].pending_text = ""
        emit('recording_started', {'status': 'recording'})

@socketio.on('audio_data')
def handle_audio_data(data):
    """æ¥æ”¶éŸ³é¢‘æ•°æ®"""
    sid = request.sid
    if sid not in sessions:
        return
    
    session = sessions[sid]
    
    # æ·»åŠ éŸ³é¢‘æ•°æ®
    audio_bytes = data.get('audio')
    if audio_bytes:
        session.add_audio(audio_bytes)
        
        # å¤„ç†éŸ³é¢‘å¹¶è¿”å›ç»“æœ
        result = session.process_audio()
        if result:
            emit('transcription', result)

@socketio.on('stop_recording')
def handle_stop_recording():
    """åœæ­¢å½•éŸ³"""
    sid = request.sid
    print(f"â¹ï¸ åœæ­¢å½•éŸ³: {sid}")
    if sid not in sessions:
        return
    
    session = sessions[sid]
    
    # å¤„ç†å‰©ä½™éŸ³é¢‘
    result = session.finalize()
    if result:
        emit('transcription', result)
    
    emit('recording_stopped', {'status': 'stopped'})

if __name__ == '__main__':
    print("=" * 60)
    print("ğŸ™ï¸ å®æ—¶ä¸­æ–‡è¯­éŸ³è¯†åˆ«æœåŠ¡å™¨")
    print("=" * 60)
    print("ğŸ“ åŠŸèƒ½:")
    print("  - å®æ—¶æµå¼è¯­éŸ³è¯†åˆ« (600mså»¶è¿Ÿ)")
    print("  - è¯­éŸ³ç«¯ç‚¹æ£€æµ‹ (VAD)")
    print("  - è‡ªåŠ¨æ ‡ç‚¹æ¢å¤")
    print("  - ä¸­æ–‡ä¸“ç”¨ä¼˜åŒ–")
    print("=" * 60)
    print("ğŸ”§ æ¨¡å‹:")
    print("  - ASR: paraformer-zh-streaming")
    print("  - VAD: fsmn-vad")
    print("  - æ ‡ç‚¹: ct-punc")
    print("=" * 60)
    print("ğŸŒ è®¿é—®åœ°å€: http://localhost:5005")
    print("=" * 60)
    
    # é¢„åŠ è½½æ¨¡å‹
    init_models()
    
    # å¯åŠ¨æœåŠ¡å™¨
    socketio.run(app, host='0.0.0.0', port=5005, debug=False)

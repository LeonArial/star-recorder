import React, { useState, useRef, useCallback, useEffect } from 'react';
import { io, Socket } from 'socket.io-client';
import { Mic, MicOff, Loader2, Copy, Trash2, Download, Sparkles } from 'lucide-react';
import AudioVisualizer from './AudioVisualizer';
import AudioPlayer from './AudioPlayer';
import { API_BASE_URL } from '../services/asrService';

interface FinalResult {
  paraformer: string;
  sensevoice: string;
  llm_merged: string;
  paraformer_length: number;
  sensevoice_length: number;
  llm_merged_length: number;
}

const RealTimeTranscriber: React.FC = () => {
  const [isRecording, setIsRecording] = useState(false);
  const [transcript, setTranscript] = useState<string>("");
  const [stream, setStream] = useState<MediaStream | null>(null);
  const [error, setError] = useState<string | null>(null);
  const [isConnecting, setIsConnecting] = useState(false);
  const [audioUrl, setAudioUrl] = useState<string | null>(null);
  const [isProcessingLLM, setIsProcessingLLM] = useState(false);

  // Refs
  const socketRef = useRef<Socket | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const processorRef = useRef<ScriptProcessorNode | null>(null);
  const sourceRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);

  // æ¸…ç† Socket è¿æ¥
  useEffect(() => {
    return () => {
      if (socketRef.current) {
        socketRef.current.disconnect();
      }
    };
  }, []);

  // åœæ­¢å½•éŸ³
  const stopRecording = useCallback(async () => {
    console.log('åœæ­¢å½•éŸ³...');
    
    // é€šçŸ¥æœåŠ¡å™¨åœæ­¢å½•éŸ³ï¼ˆå¦‚æœsocketè¿˜è¿æ¥ç€ï¼‰
    if (socketRef.current && socketRef.current.connected) {
      socketRef.current.emit('stop_recording');
    }
    
    // Stop MediaRecorder
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop();
    }

    // åœæ­¢éŸ³é¢‘æµ
    if (stream) {
      stream.getTracks().forEach(track => track.stop());
      setStream(null);
    }

    // æ¸…ç†éŸ³é¢‘å¤„ç†èŠ‚ç‚¹
    if (processorRef.current) {
      processorRef.current.disconnect();
      processorRef.current = null;
    }

    if (sourceRef.current) {
      sourceRef.current.disconnect();
      sourceRef.current = null;
    }

    if (audioContextRef.current) {
      await audioContextRef.current.close();
      audioContextRef.current = null;
    }

    setIsRecording(false);
  }, [stream]);

  const startRecording = async () => {
    setError(null);
    setIsConnecting(true);
    setAudioUrl(null);
    setTranscript("");
    setIsProcessingLLM(false);
    audioChunksRef.current = [];
    
    try {
      // 1. è¿æ¥ Socket.IOï¼ˆé…ç½®è¶…æ—¶å‚æ•°ä»¥æ”¯æŒé•¿æ—¶é—´å½•éŸ³ï¼‰
      const socket = io(API_BASE_URL, {
        transports: ['websocket'],
        // ä¸åç«¯é…ç½®åŒ¹é…ï¼Œå¢åŠ è¶…æ—¶æ—¶é—´
        timeout: 120000,  // è¿æ¥è¶…æ—¶ 120 ç§’
        reconnection: true,  // å¯ç”¨è‡ªåŠ¨é‡è¿
        reconnectionAttempts: 3,  // æœ€å¤šé‡è¿ 3 æ¬¡
        reconnectionDelay: 1000,  // é‡è¿å»¶è¿Ÿ 1 ç§’
      });

      socketRef.current = socket;

      // Socket äº‹ä»¶ç›‘å¬
      socket.on('connected', (data) => {
        console.log('âœ… å·²è¿æ¥åˆ°æœåŠ¡å™¨:', data.session_id);
        setIsConnecting(false);
        setIsRecording(true);
      });

      socket.on('recording_started', (data) => {
        console.log('ğŸ™ï¸ å½•éŸ³å·²å¼€å§‹:', data);
      });

      socket.on('transcription', (data) => {
        console.log('ğŸ“ å®æ—¶è¯†åˆ«:', data);
        // æ˜¾ç¤ºå®æ—¶æ–‡æœ¬
        if (data.full_text) {
          setTranscript(data.full_text);
        }
      });

      socket.on('final_result', (data: FinalResult) => {
        console.log('âœ… æœ€ç»ˆç»“æœ:', data);
        // è‡ªåŠ¨ç”¨LLMåˆå¹¶çš„ç»“æœæ›¿æ¢transcript
        if (data.llm_merged) {
          setTranscript(data.llm_merged);
        }
        setIsProcessingLLM(false);
        
        // æ¥æ”¶å®Œæœ€ç»ˆç»“æœåæ–­å¼€socketè¿æ¥
        console.log('ğŸ”Œ æ–­å¼€Socketè¿æ¥');
        socket.disconnect();
        socketRef.current = null;
      });

      // ç›‘å¬å½•éŸ³åœæ­¢äº‹ä»¶ï¼Œæ˜¾ç¤ºLLMå¤„ç†ä¸­
      socket.on('recording_stopped', () => {
        console.log('ğŸ›‘ å½•éŸ³å·²åœæ­¢ï¼Œå¼€å§‹LLMçº é”™...');
        setIsProcessingLLM(true);
      });

      socket.on('error', (data) => {
        console.error('âŒ é”™è¯¯:', data);
        setError(data.message || 'å‘ç”Ÿé”™è¯¯');
        setIsProcessingLLM(false);
        stopRecording();
        // é”™è¯¯æ—¶æ–­å¼€socketè¿æ¥
        socket.disconnect();
        socketRef.current = null;
      });

      socket.on('disconnect', (reason) => {
        console.log('âš ï¸ æ–­å¼€è¿æ¥ï¼ŒåŸå› :', reason);
        socketRef.current = null;
        // å¦‚æœæ˜¯æœåŠ¡å™¨ä¸»åŠ¨æ–­å¼€æˆ–ä¼ è¾“é”™è¯¯ï¼Œæ˜¾ç¤ºæç¤º
        if (reason === 'transport error' || reason === 'transport close') {
          setError('è¿æ¥ä¸­æ–­ï¼Œè¯·æ£€æŸ¥ç½‘ç»œåé‡è¯•');
          setIsProcessingLLM(false);
        }
      });

      // é‡è¿äº‹ä»¶
      socket.on('reconnect_attempt', (attempt) => {
        console.log(`ğŸ”„ æ­£åœ¨å°è¯•é‡è¿ (${attempt}/3)...`);
      });

      socket.on('reconnect', () => {
        console.log('âœ… é‡è¿æˆåŠŸ');
      });

      socket.on('reconnect_failed', () => {
        console.log('âŒ é‡è¿å¤±è´¥');
        setError('è¿æ¥æ–­å¼€ä¸”é‡è¿å¤±è´¥ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•');
        setIsProcessingLLM(false);
      });

      // 2. è·å–éº¦å…‹é£
      const mediaStream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
        } 
      });
      setStream(mediaStream);

      // 3. åˆå§‹åŒ– MediaRecorderï¼ˆç”¨äºä¸‹è½½å½•éŸ³ï¼‰
      const recorder = new MediaRecorder(mediaStream);
      recorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          audioChunksRef.current.push(e.data);
        }
      };
      recorder.onstop = () => {
        const blob = new Blob(audioChunksRef.current, { type: recorder.mimeType || 'audio/webm' });
        const url = URL.createObjectURL(blob);
        setAudioUrl(url);
      };
      recorder.start();
      mediaRecorderRef.current = recorder;

      // 4. è®¾ç½®éŸ³é¢‘å¤„ç†
      const audioCtx = new (window.AudioContext || (window as any).webkitAudioContext)({ sampleRate: 16000 });
      audioContextRef.current = audioCtx;

      const source = audioCtx.createMediaStreamSource(mediaStream);
      sourceRef.current = source;

      const processor = audioCtx.createScriptProcessor(4096, 1, 1);
      processorRef.current = processor;

      processor.onaudioprocess = (e) => {
        const inputData = e.inputBuffer.getChannelData(0);
        
        // è½¬æ¢ä¸º Int16Array
        const int16Data = new Int16Array(inputData.length);
        for (let i = 0; i < inputData.length; i++) {
          const s = Math.max(-1, Math.min(1, inputData[i]));
          int16Data[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
        }
        
        // å‘é€éŸ³é¢‘æ•°æ®åˆ°æœåŠ¡å™¨
        if (socket && socket.connected) {
          socket.emit('audio_data', int16Data.buffer);
        }
      };

      source.connect(processor);
      processor.connect(audioCtx.destination);

      // 5. é€šçŸ¥æœåŠ¡å™¨å¼€å§‹å½•éŸ³
      socket.emit('start_recording');

    } catch (err: any) {
      console.error("å¯åŠ¨å½•éŸ³å¤±è´¥:", err);
      setError(err.message || "æ— æ³•è®¿é—®éº¦å…‹é£æˆ–è¿æ¥åˆ°æœåŠ¡å™¨");
      setIsConnecting(false);
      setIsProcessingLLM(false);
      stopRecording();
      // å¯åŠ¨å¤±è´¥æ—¶æ–­å¼€socket
      if (socketRef.current) {
        socketRef.current.disconnect();
        socketRef.current = null;
      }
    }
  };

  const handleCopy = (text: string) => {
    navigator.clipboard.writeText(text);
  };

  const handleClear = () => {
    setTranscript("");
    setIsProcessingLLM(false);
  };

  return (
    <div className="flex flex-col w-full max-w-4xl mx-auto gap-6">
      {/* Top Section: Visualizer / Player & Controls */}
      <div className="rounded-2xl p-6">
        <div className="flex flex-col items-center gap-6">
          
          {/* Audio Visualization or Player */}
          <div className="w-full">
             {!isRecording && audioUrl ? (
                <AudioPlayer audioUrl={audioUrl} />
             ) : (
                <div className="relative w-full h-32 rounded-xl overflow-hidden flex items-center justify-center">
                   <AudioVisualizer stream={stream} isRecording={isRecording} />
                   {!isRecording && !isConnecting && (
                      <div className="absolute inset-0 flex items-center justify-center text-slate-400 text-sm font-medium pointer-events-none">
                        å‡†å¤‡å°±ç»ªï¼Œç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¼€å§‹å½•éŸ³
                      </div>
                   )}
                </div>
             )}
          </div>

          {/* Controls */}
          <div className="flex items-center gap-4">
            {!isRecording ? (
              <button
                onClick={startRecording}
                disabled={isConnecting}
                className={`flex items-center gap-2 px-8 py-3 rounded-full font-semibold text-white shadow-lg transition-all active:scale-95 ${
                    isConnecting
                    ? 'bg-slate-300 cursor-not-allowed'
                    : 'bg-blue-600 hover:bg-blue-700 shadow-blue-500/30 hover:shadow-blue-500/40'
                }`}
              >
                {isConnecting ? <Loader2 className="w-5 h-5 animate-spin" /> : <Mic className="w-5 h-5" />}
                {isConnecting ? 'è¿æ¥ä¸­...' : (audioUrl ? 'é‡æ–°å½•éŸ³' : 'å¼€å§‹å½•éŸ³')}
              </button>
            ) : (
              <button
                onClick={stopRecording}
                className="flex items-center gap-2 px-8 py-3 rounded-full font-semibold text-white bg-red-500 hover:bg-red-600 shadow-lg shadow-red-500/30 hover:shadow-red-500/40 transition-all active:scale-95"
              >
                <MicOff className="w-5 h-5" />
                åœæ­¢å½•éŸ³
              </button>
            )}
            
             {/* Download Button (Small) */}
             {!isRecording && audioUrl && (
               <a
                href={audioUrl}
                download={`recording-${new Date().toISOString()}.webm`}
                className="p-3 rounded-full border border-slate-200 text-slate-600 hover:text-blue-600 hover:bg-blue-50 transition-all"
                title="ä¸‹è½½å½•éŸ³"
               >
                 <Download className="w-5 h-5" />
               </a>
             )}
          </div>

          {/* Error Message */}
          {error && (
            <div className="text-sm text-red-600 bg-red-50 px-4 py-2 rounded-lg border border-red-100">
              {error}
            </div>
          )}
        </div>
      </div>

      {/* Bottom Section: Transcript */}
      <div className="bg-white border border-slate-200 rounded-2xl shadow-sm flex flex-col overflow-hidden min-h-[400px]">
        {/* Toolbar */}
        <div className="border-b border-slate-100 px-4 py-3 flex items-center justify-between bg-slate-50/50">
            <div className="flex items-center gap-2">
                <span className="text-sm font-semibold text-slate-700">è½¬å†™ç»“æœ</span>
                {isProcessingLLM && (
                    <div className="flex items-center gap-1.5 px-2 py-0.5 bg-blue-50 text-blue-600 rounded text-xs font-medium border border-blue-100">
                        <Sparkles className="w-3 h-3 animate-pulse" />
                        AI ä¼˜åŒ–ä¸­...
                    </div>
                )}
            </div>
            <div className="flex items-center gap-1">
                <button 
                    onClick={() => handleCopy(transcript)}
                    disabled={!transcript}
                    className="p-1.5 text-slate-400 hover:text-blue-600 hover:bg-blue-50 rounded-lg transition-colors disabled:opacity-50"
                    title="å¤åˆ¶å…¨éƒ¨"
                >
                    <Copy className="w-4 h-4" />
                </button>
                <button 
                    onClick={handleClear}
                    disabled={!transcript}
                    className="p-1.5 text-slate-400 hover:text-red-500 hover:bg-red-50 rounded-lg transition-colors disabled:opacity-50"
                    title="æ¸…ç©º"
                >
                    <Trash2 className="w-4 h-4" />
                </button>
            </div>
        </div>

        {/* Text Area */}
        <div className="flex-1 relative">
             <textarea
                readOnly
                value={transcript}
                placeholder="ç­‰å¾…å½•éŸ³..."
                className="w-full h-full p-6 resize-none outline-none text-slate-700 text-sm leading-relaxed bg-transparent font-sans"
            />
        </div>
      </div>
    </div>
  );
};

export default RealTimeTranscriber;

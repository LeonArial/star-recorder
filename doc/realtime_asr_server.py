"""
å®æ—¶è¯­éŸ³è¯†åˆ«æœåŠ¡å™¨
æ”¯æŒ WebSocket å®æ—¶ä¼ è¾“éŸ³é¢‘æ•°æ®å¹¶è¿”å›è¯†åˆ«ç»“æœ
"""
import asyncio
import json
import os
import tempfile
import wave
import numpy as np
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess
import soundfile as sf
import time
import threading
import requests
import re

app = Flask(__name__)
app.config['SECRET_KEY'] = 'sensevoice-realtime-asr'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# å…¨å±€æ¨¡å‹å®ä¾‹
asr_model = None
punc_model = None
sensevoice_model = None

# LLMé…ç½®
LLM_API_URL = "http://10.8.75.207:9997/v1/chat/completions"
LLM_API_KEY = "sk-dmowsenrtifmlnpmlhaatxgkxnhbmusjfzgnofvlhtblslwa"
LLM_MODEL = "qwen3:8b"

# æ¨¡å‹åŠ è½½é”
model_lock = threading.Lock()

def init_models():
    """åˆå§‹åŒ– ASRã€æ ‡ç‚¹ä¸å¤æ£€æ¨¡å‹"""
    global asr_model, punc_model, sensevoice_model
    
    with model_lock:
        if asr_model is None:
            print("ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹...")
            
            # åŠ è½½ä¸­æ–‡æµå¼ ASR æ¨¡å‹
            print("  - åŠ è½½ ASR æ¨¡å‹: paraformer-zh-streaming")
            asr_model = AutoModel(
                model="paraformer-zh-streaming",
                device="cuda:0",  # æ”¹ä¸º "cuda:0" ä½¿ç”¨ GPU
                disable_update=True,
            )
            
            # åŠ è½½æ ‡ç‚¹æ¢å¤æ¨¡å‹
            print("  - åŠ è½½æ ‡ç‚¹æ¨¡å‹: ct-punc")
            punc_model = AutoModel(
                model="ct-punc",
                device="cuda:0",
                disable_update=True,
            )
            
            # SenseVoice å¤æ£€æ¨¡å‹ï¼ˆé…ç½®VADï¼‰
            print("  - åŠ è½½å¤æ£€æ¨¡å‹: SenseVoiceSmall")
            sensevoice_model = AutoModel(
                model="iic/SenseVoiceSmall",
                vad_model="fsmn-vad",
                vad_kwargs={"max_single_segment_time": 30000},
                device="cuda:0",
                disable_update=True,
            )
            
            print("âœ… æ‰€æœ‰æ¨¡å‹åŠ è½½å®Œæˆï¼")


def _run_sensevoice(audio_samples, sample_rate):
    """è°ƒç”¨ SenseVoiceSmall å¯¹éŸ³é¢‘æ®µè¿›è¡Œå¤æ£€"""
    if audio_samples.size == 0:
        return ""

    temp_path = None
    try:
        temp_path = _save_temp_wav(audio_samples, sample_rate)
        result = sensevoice_model.generate(
            input=temp_path,
            cache={},
            language="auto",  # è‡ªåŠ¨æ£€æµ‹è¯­è¨€
            use_itn=False,     # ä½¿ç”¨é€†æ–‡æœ¬æ­£åˆ™åŒ–
            batch_size_s=60,  # æ‰¹å¤„ç†å¤§å°
            merge_vad=True,   # åˆå¹¶VADç»“æœ
        )
        if result and len(result) > 0:
            raw_text = result[0].get("text", "")
            # ä½¿ç”¨å®˜æ–¹çš„å¯Œæ–‡æœ¬åå¤„ç†å‡½æ•°æ¸…ç†ç‰¹æ®Šæ ‡è®°
            clean_text = rich_transcription_postprocess(raw_text)
            return clean_text
        return ""
    finally:
        if temp_path and os.path.exists(temp_path):
            os.remove(temp_path)


def _save_temp_wav(samples, sample_rate):
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    tmp.close()
    audio_int16 = np.clip(samples, -1, 1)
    audio_int16 = (audio_int16 * 32767).astype(np.int16)
    with wave.open(tmp.name, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(sample_rate)
        wf.writeframes(audio_int16.tobytes())
    return tmp.name


def _call_llm_merge(paraformer_text, sensevoice_text, hotwords=None):
    """è°ƒç”¨LLMå¯¹ä¸¤ä¸ªè¯†åˆ«ç»“æœè¿›è¡Œæ£€æŸ¥ã€çº é”™ã€åˆå¹¶"""
    
    # æ„å»ºç³»ç»Ÿæç¤ºè¯
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¯­éŸ³è¯†åˆ«ç»“æœæ ¡å¯¹åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š

1. **å¯¹æ¯”åˆ†æ**ï¼šå¯¹æ¯”ä¸¤ä¸ªè¯­éŸ³è¯†åˆ«æ¨¡å‹çš„è¾“å‡ºç»“æœ
   - Paraformerï¼šå®æ—¶æµå¼è¯†åˆ«ç»“æœï¼Œé€Ÿåº¦å¿«ä½†å‡†ç¡®åº¦ç›¸å¯¹è¾ƒä½ï¼Œå¯èƒ½å­˜åœ¨è¾ƒå¤šé”™è¯¯
   - SenseVoiceï¼šå®Œæ•´éŸ³é¢‘è¯†åˆ«ç»“æœï¼Œå‡†ç¡®åº¦é«˜ï¼Œè´¨é‡æ›´å¯é 

2. **çº é”™åˆå¹¶ç­–ç•¥**ï¼š
   - ä¼˜å…ˆé‡‡ç”¨SenseVoiceçš„ç»“æœï¼Œå®ƒçš„å‡†ç¡®åº¦æ˜æ˜¾é«˜äºParaformer
   - åœ¨SenseVoiceæ˜æ˜¾æœ‰ä¸åˆç†çš„æƒ…å†µä¸‹ï¼Œå‚è€ƒParaformerè¿›è¡Œè¡¥å……
   - è¯†åˆ«å¹¶çº æ­£è¯†åˆ«é”™è¯¯ï¼ˆåŒéŸ³å­—ã€å¤šå­—ã€å°‘å­—ã€é”™åˆ«å­—ã€æ ‡ç‚¹ç¬¦å·ç­‰ï¼‰
   - ä¿æŒè¯­å¥é€šé¡ºã€è¯­ä¹‰è¿è´¯

3. **è¾“å‡ºè¦æ±‚**ï¼š
   - åªè¾“å‡ºæœ€ç»ˆçº æ­£åçš„æ–‡æœ¬ï¼Œä¸è¦ä»»ä½•è§£é‡Šè¯´æ˜
   - ä¸è¦æ·»åŠ ä¸å­˜åœ¨çš„å†…å®¹
"""

    # å¦‚æœæœ‰çƒ­è¯ï¼Œæ·»åŠ åˆ°æç¤ºè¯ä¸­
    if hotwords and len(hotwords) > 0:
        hotword_list = "ã€".join(hotwords)
        system_prompt += f"\n\n5. **ä¸“ä¸šè¯æ±‡**ï¼ˆä¼˜å…ˆä½¿ç”¨è¿™äº›è¯æ±‡ï¼‰ï¼š\n{hotword_list}"
    
    # æ„å»ºç”¨æˆ·è¾“å…¥
    user_content = f"""è¯·æ£€æŸ¥ã€çº é”™å¹¶åˆå¹¶ä»¥ä¸‹ä¸¤ä¸ªè¯­éŸ³è¯†åˆ«ç»“æœï¼š

**Paraformerè¯†åˆ«ç»“æœ**ï¼š
{paraformer_text}

**SenseVoiceè¯†åˆ«ç»“æœ**ï¼š
{sensevoice_text}

è¯·è¾“å‡ºçº æ­£åçš„æœ€ç»ˆæ–‡æœ¬ï¼š"""
    
    try:
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {LLM_API_KEY}'
        }
        
        data = {
            "model": LLM_MODEL,
            "messages": [
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": user_content
                }
            ],
            "temperature": 0.3,  # è¾ƒä½æ¸©åº¦ï¼Œä¿æŒç»“æœç¨³å®š
            "max_tokens": 2000
        }
        
        print(f"ğŸ¤– æ­£åœ¨è°ƒç”¨LLMåˆå¹¶ç»“æœ...")
        response = requests.post(LLM_API_URL, headers=headers, json=data, timeout=30)
        result = response.json()
        
        if "choices" in result and len(result["choices"]) > 0:
            merged_text = result["choices"][0]["message"]["content"].strip()
            
            # è¿‡æ»¤æ‰ <think> æ ‡ç­¾åŠå…¶å†…å®¹
            think_pattern = r"<think>.*?</think>"
            merged_text = re.sub(think_pattern, "", merged_text, flags=re.DOTALL).strip()
            
            print(f"âœ… LLMåˆå¹¶å®Œæˆ")
            return merged_text
        else:
            raise Exception(f"LLMå“åº”æ ¼å¼é”™è¯¯: {result}")
            
    except Exception as e:
        error_msg = f"LLMè°ƒç”¨å¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}")
        # å¦‚æœLLMå¤±è´¥ï¼Œè¿”å›SenseVoiceç»“æœä½œä¸ºåå¤‡
        return sensevoice_text if sensevoice_text else paraformer_text


class RealtimeASR:
    """å®æ—¶è¯­éŸ³è¯†åˆ«å¤„ç†å™¨"""
    
    def __init__(self, session_id):
        self.session_id = session_id
        self.audio_buffer = []
        self.sample_rate = 16000
        self.is_processing = False
        self.last_result = ""
        self.cache = {}  # æµå¼è¯†åˆ«ç¼“å­˜
        self.chunk_size = [0, 10, 5]  # [0, 10, 5] è¡¨ç¤º600mså®æ—¶å‡ºå­—ï¼Œ300msæœªæ¥ä¿¡æ¯
        self.chunk_stride = self.chunk_size[1] * 960  # 600mså¯¹åº”çš„é‡‡æ ·ç‚¹æ•°
        self.all_text = ""  # ç´¯ç§¯æ‰€æœ‰è¯†åˆ«æ–‡æœ¬ï¼ˆæ— æ ‡ç‚¹ï¼‰
        self.text_with_punc = ""  # å·²æ·»åŠ æ ‡ç‚¹çš„æ–‡æœ¬
        self.pending_text = ""  # ç­‰å¾…æ ‡ç‚¹çš„æ–‡æœ¬
        self.punc_threshold = 30  # ç´¯ç§¯åˆ°30å­—ç¬¦æ—¶åšæ ‡ç‚¹
        self.full_audio = []  # å®Œæ•´å½•éŸ³ç¼“å­˜ï¼ˆç”¨äºSenseVoiceï¼‰
        
    def add_audio(self, audio_data):
        """æ·»åŠ éŸ³é¢‘æ•°æ®åˆ°ç¼“å†²åŒº"""
        try:
            # ç¡®ä¿æ•°æ®é•¿åº¦æ˜¯ 2 çš„å€æ•°ï¼ˆint16 = 2 bytesï¼‰
            if len(audio_data) % 2 != 0:
                # å¦‚æœä¸æ˜¯å¶æ•°ï¼Œæˆªæ–­æœ€åä¸€ä¸ªå­—èŠ‚
                audio_data = audio_data[:-1]
            
            if len(audio_data) == 0:
                return
            
            # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸º float32 numpy æ•°ç»„
            audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0
            self.audio_buffer.extend(audio_np)
            self.full_audio.extend(audio_np)  # ä¿å­˜å®Œæ•´éŸ³é¢‘ç”¨äºæœ€åçš„SenseVoiceè¯†åˆ«
        except Exception as e:
            error_msg = f"éŸ³é¢‘æ•°æ®å¤„ç†é”™è¯¯: {str(e)}, æ•°æ®é•¿åº¦: {len(audio_data)}"
            print(f"âŒ {error_msg}")
            socketio.emit('error', {
                'type': 'audio_processing_error',
                'message': error_msg
            }, to=self.session_id)
        
    def process_audio(self):
        """å¤„ç†ç¼“å†²åŒºä¸­çš„éŸ³é¢‘ï¼ˆæµå¼ï¼‰"""
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„éŸ³é¢‘æ•°æ®ï¼ˆ600msï¼‰
        if len(self.audio_buffer) < self.chunk_stride:
            return None
        
        try:
            # å–å‡ºä¸€ä¸ª chunk çš„éŸ³é¢‘
            speech_chunk = np.array(self.audio_buffer[:self.chunk_stride], dtype=np.float32)
            
            # æµå¼ ASR è¯†åˆ«
            asr_result = asr_model.generate(
                input=speech_chunk,
                cache=self.cache,
                is_final=False,
                chunk_size=self.chunk_size,
                encoder_chunk_look_back=4,
                decoder_chunk_look_back=1,
            )
            
            if asr_result and len(asr_result) > 0:
                text = asr_result[0]["text"]
                
                # ç´¯ç§¯åŸå§‹æ–‡æœ¬
                self.all_text += text
                self.pending_text += text
                
                # ç§»é™¤å·²å¤„ç†çš„éŸ³é¢‘
                self.audio_buffer = self.audio_buffer[self.chunk_stride:]
                
                # å¢é‡æ ‡ç‚¹æ¢å¤ï¼ˆç´¯ç§¯åˆ°é˜ˆå€¼æ—¶å¤„ç†ï¼‰
                punc_text = ""
                if len(self.pending_text) >= self.punc_threshold and punc_model:
                    try:
                        # å¯¹å¾…å¤„ç†æ–‡æœ¬åšæ ‡ç‚¹
                        punc_result = punc_model.generate(input=self.pending_text)
                        if punc_result and len(punc_result) > 0:
                            punc_text = punc_result[0]["text"]
                            
                            # ä¿ç•™æœ€å10ä¸ªå­—ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œé¿å…æ–­å¥ä¸è¿è´¯
                            if len(self.pending_text) > 10:
                                # å·²ç¡®è®¤çš„å¸¦æ ‡ç‚¹æ–‡æœ¬
                                confirmed = punc_text[:-10] if len(punc_text) > 10 else ""
                                self.text_with_punc += confirmed
                                
                                # å‰©ä½™éƒ¨åˆ†ç»§ç»­ç­‰å¾…
                                self.pending_text = self.pending_text[-10:]
                            else:
                                self.text_with_punc += punc_text
                                self.pending_text = ""
                    except Exception as e:
                        error_msg = f"å¢é‡æ ‡ç‚¹å¤±è´¥: {str(e)}"
                        print(f"âš ï¸ {error_msg}")
                        socketio.emit('warning', {
                            'type': 'punctuation_error',
                            'message': error_msg
                        }, to=self.session_id)
                
                # è¿”å›å¢é‡ç»“æœ
                return {
                    "text": text,  # åŸå§‹æ–°å¢æ–‡æœ¬
                    "full_text_with_punc": self.text_with_punc + self.pending_text,  # å®Œæ•´å¸¦æ ‡ç‚¹æ–‡æœ¬
                    "is_final": False,
                }
            else:
                self.audio_buffer = self.audio_buffer[self.chunk_stride:]
        except Exception as e:
            error_msg = f"ASRè¯†åˆ«é”™è¯¯: {str(e)}"
            print(f"âŒ {error_msg}")
            import traceback
            traceback.print_exc()
            socketio.emit('error', {
                'type': 'asr_recognition_error',
                'message': error_msg
            }, to=self.session_id)
            
        return None
    
    def finalize(self):
        """å¤„ç†å‰©ä½™çš„éŸ³é¢‘å¹¶è¿”å›æœ€ç»ˆç»“æœ"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å‰©ä½™éŸ³é¢‘æˆ–ç¼“å­˜å†…å®¹
            if len(self.audio_buffer) > 0:
                # æœ‰å‰©ä½™éŸ³é¢‘ï¼šéœ€è¦å¡«å……åˆ°chunk_strideä»¥ä¿æŒç»´åº¦ä¸€è‡´
                remaining_len = len(self.audio_buffer)
                
                # å¦‚æœå‰©ä½™éŸ³é¢‘ä¸è¶³ä¸€ä¸ªchunkï¼Œç”¨0å¡«å……
                if remaining_len < self.chunk_stride:
                    padding_len = self.chunk_stride - remaining_len
                    padded_audio = np.concatenate([
                        np.array(self.audio_buffer, dtype=np.float32),
                        np.zeros(padding_len, dtype=np.float32)
                    ])
                    speech_chunk = padded_audio
                else:
                    # å‰©ä½™éŸ³é¢‘è¶…è¿‡ä¸€ä¸ªchunkï¼Œåªå–chunk_strideé•¿åº¦
                    speech_chunk = np.array(self.audio_buffer[:self.chunk_stride], dtype=np.float32)
                
                # æœ€åä¸€ä¸ªchunkï¼Œè®¾ç½® is_final=True å¼ºåˆ¶è¾“å‡ºç¼“å­˜
                asr_result = asr_model.generate(
                    input=speech_chunk,
                    cache=self.cache,
                    is_final=True,  # å¼ºåˆ¶è¾“å‡ºæœ€åä¸€ä¸ªå­—
                    chunk_size=self.chunk_size,
                    encoder_chunk_look_back=4,
                    decoder_chunk_look_back=1,
                )
            elif self.cache:
                # æ²¡æœ‰å‰©ä½™éŸ³é¢‘ä½†æœ‰ç¼“å­˜ï¼šå‘é€ä¸€ä¸ªå®Œæ•´çš„é™éŸ³chunk
                speech_chunk = np.zeros(self.chunk_stride, dtype=np.float32)  # 600ms é™éŸ³
                
                asr_result = asr_model.generate(
                    input=speech_chunk,
                    cache=self.cache,
                    is_final=True,
                    chunk_size=self.chunk_size,
                    encoder_chunk_look_back=4,
                    decoder_chunk_look_back=1,
                )
            else:
                # æ—¢æ²¡æœ‰å‰©ä½™éŸ³é¢‘ä¹Ÿæ²¡æœ‰ç¼“å­˜ï¼šç›´æ¥è¿”å›å·²æœ‰æ–‡æœ¬
                asr_result = None
            
            if asr_result and len(asr_result) > 0:
                text = asr_result[0]["text"]
                if text:  # åªæœ‰éç©ºæ–‡æœ¬æ‰ç´¯ç§¯
                    self.all_text += text
                    self.pending_text += text
                    print(f"ğŸ“ æœ€ç»ˆè¯†åˆ«: {text}")
            
            # å¯¹å‰©ä½™å¾…å¤„ç†æ–‡æœ¬è¿›è¡Œæœ€ç»ˆæ ‡ç‚¹æ¢å¤
            if self.pending_text and punc_model:
                try:
                    punc_result = punc_model.generate(input=self.pending_text)
                    if punc_result and len(punc_result) > 0:
                        self.text_with_punc += punc_result[0]["text"]
                except Exception as e:
                    error_msg = f"æœ€ç»ˆæ ‡ç‚¹æ¢å¤å¤±è´¥: {str(e)}"
                    print(f"âš ï¸ {error_msg}")
                    socketio.emit('warning', {
                        'type': 'final_punctuation_error',
                        'message': error_msg
                    }, to=self.session_id)
                    self.text_with_punc += self.pending_text
            else:
                self.text_with_punc += self.pending_text
            
            paraformer_text = self.text_with_punc
            
            print(f"âœ… Paraformerå®Œæ•´æ–‡æœ¬: {paraformer_text}")
            print(f"ğŸ“Š æ€»å­—æ•°: {len(paraformer_text)}")
            
            # ä½¿ç”¨SenseVoiceå¯¹å®Œæ•´éŸ³é¢‘è¿›è¡Œè¯†åˆ«
            sensevoice_text = ""
            if len(self.full_audio) > 0:
                print(f"ğŸ” å¼€å§‹SenseVoiceå®Œæ•´è¯†åˆ«...")
                try:
                    audio_array = np.array(self.full_audio, dtype=np.float32)
                    sensevoice_text = _run_sensevoice(audio_array, self.sample_rate)
                    print(f"âœ… SenseVoiceå®Œæ•´æ–‡æœ¬: {sensevoice_text}")
                    print(f"ğŸ“Š SenseVoiceå­—æ•°: {len(sensevoice_text)}")
                except Exception as e:
                    error_msg = f"SenseVoiceå®Œæ•´è¯†åˆ«å¤±è´¥: {str(e)}"
                    print(f"âŒ {error_msg}")
                    socketio.emit('warning', {
                        'type': 'sensevoice_full_error',
                        'message': error_msg
                    }, to=self.session_id)
            
            # è°ƒç”¨LLMåˆå¹¶çº é”™ï¼ˆå¦‚æœä¸¤ä¸ªç»“æœéƒ½æœ‰å†…å®¹ï¼‰
            llm_merged_text = ""
            if paraformer_text or sensevoice_text:
                llm_merged_text = _call_llm_merge(paraformer_text, sensevoice_text)
                print(f"âœ… LLMåˆå¹¶æ–‡æœ¬: {llm_merged_text}")
                print(f"ğŸ“Š LLMå­—æ•°: {len(llm_merged_text)}")
            
            # å‘é€ä¸‰ç§ç»“æœåˆ°å‰ç«¯
            socketio.emit('final_comparison', {
                'paraformer': paraformer_text,
                'sensevoice': sensevoice_text,
                'llm_merged': llm_merged_text,
                'paraformer_length': len(paraformer_text),
                'sensevoice_length': len(sensevoice_text),
                'llm_merged_length': len(llm_merged_text),
            }, to=self.session_id)
            
            # æ¸…ç©ºæ‰€æœ‰çŠ¶æ€
            self.audio_buffer = []
            self.cache = {}
            self.all_text = ""
            self.text_with_punc = ""
            self.pending_text = ""
            self.full_audio = []
            
            return {
                "text": paraformer_text,
                "full_text_with_punc": paraformer_text,
                "is_final": True,
            }
        except Exception as e:
            error_msg = f"æœ€ç»ˆè¯†åˆ«é”™è¯¯: {str(e)}"
            print(f"âŒ {error_msg}")
            import traceback
            traceback.print_exc()
            socketio.emit('error', {
                'type': 'finalization_error',
                'message': error_msg
            }, to=self.session_id)
            
            # å³ä½¿å‡ºé”™ï¼Œä¹Ÿè¿”å›å·²æœ‰çš„æ–‡æœ¬
            return {
                "text": self.text_with_punc + self.pending_text,
                "full_text_with_punc": self.text_with_punc + self.pending_text,
                "is_final": True,
            }
    

# å­˜å‚¨æ‰€æœ‰ä¼šè¯
sessions = {}

@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('realtime_asr.html')

@socketio.on('connect')
def handle_connect():
    """å®¢æˆ·ç«¯è¿æ¥"""
    sid = request.sid
    print(f"âœ… å®¢æˆ·ç«¯è¿æ¥: {sid}")
    
    # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
    if asr_model is None:
        init_models()
    
    # åˆ›å»ºæ–°ä¼šè¯
    sessions[sid] = RealtimeASR(sid)
    emit('connected', {'status': 'ready'})

@socketio.on('disconnect')
def handle_disconnect():
    """å®¢æˆ·ç«¯æ–­å¼€"""
    sid = request.sid
    print(f"âŒ å®¢æˆ·ç«¯æ–­å¼€: {sid}")
    if sid in sessions:
        del sessions[sid]

@socketio.on('start_recording')
def handle_start_recording():
    """å¼€å§‹å½•éŸ³"""
    sid = request.sid
    print(f"ğŸ™ï¸ å¼€å§‹å½•éŸ³: {sid}")
    if sid in sessions:
        sessions[sid].audio_buffer = []
        sessions[sid].cache = {}
        sessions[sid].all_text = ""
        sessions[sid].text_with_punc = ""
        sessions[sid].pending_text = ""
        sessions[sid].full_audio = []  # æ¸…ç©ºå®Œæ•´å½•éŸ³ç¼“å­˜
        emit('recording_started', {'status': 'recording'})

@socketio.on('audio_data')
def handle_audio_data(data):
    """æ¥æ”¶éŸ³é¢‘æ•°æ®"""
    sid = request.sid
    if sid not in sessions:
        return
    
    session = sessions[sid]
    
    # æ·»åŠ éŸ³é¢‘æ•°æ®
    audio_bytes = data.get('audio')
    if audio_bytes:
        session.add_audio(audio_bytes)
        
        # å¤„ç†éŸ³é¢‘å¹¶è¿”å›ç»“æœ
        result = session.process_audio()
        if result:
            emit('transcription', result)

@socketio.on('stop_recording')
def handle_stop_recording():
    """åœæ­¢å½•éŸ³"""
    sid = request.sid
    print(f"â¹ï¸ åœæ­¢å½•éŸ³: {sid}")
    if sid not in sessions:
        return
    
    session = sessions[sid]
    
    # å¤„ç†å‰©ä½™éŸ³é¢‘
    result = session.finalize()
    if result:
        emit('transcription', result)
    
    emit('recording_stopped', {'status': 'stopped'})

if __name__ == '__main__':
    print("=" * 60)
    print("ğŸ“£ å®æ—¶ä¸­æ–‡è¯­éŸ³è¯†åˆ«æœåŠ¡å™¨")
    print("=" * 60)
    print("ğŸ“ åŠŸèƒ½:")
    print("  - å®æ—¶æµå¼è¯­éŸ³è¯†åˆ« (Paraformer, 600mså»¶è¿Ÿ)")
    print("  - è‡ªåŠ¨æ ‡ç‚¹æ¢å¤")
    print("  - SenseVoiceå®Œæ•´å½•éŸ³è¯†åˆ«")
    print("  - LLMæ™ºèƒ½åˆå¹¶çº é”™")
    print("  - ä¸‰æ å¯¹æ¯”æ˜¾ç¤ºè¯†åˆ«ç»“æœ")
    print("  - æ”¯æŒçƒ­è¯å¢å¼ºï¼ˆåç»­ç‰ˆæœ¬ï¼‰")
    print("  - ä¸­æ–‡ä¸“ç”¨ä¼˜åŒ–")
    print("=" * 60)
    print("ğŸ”§ æ¨¡å‹:")
    print("  - ASR: paraformer-zh-streaming")
    print("  - æ ‡ç‚¹: ct-punc")
    print("  - å¤æ£€: SenseVoiceSmall")
    print("=" * 60)
    print("ğŸŒ è®¿é—®åœ°å€: http://localhost:5005")
    print("=" * 60)
    
    # é¢„åŠ è½½æ¨¡å‹
    init_models()
    
    # å¯åŠ¨æœåŠ¡å™¨
    socketio.run(app, host='0.0.0.0', port=5005, debug=False)

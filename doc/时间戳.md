## 模型原理介绍

Timestamp Prediction Model

目前大部分工业语音识别系统使用外接的强制对齐模型预测ASR模型识别结果的时间戳，这引入了额外的计算开销与时间开销，FunASR提供一种在ASR任务过程中天然的预测识别结果时间戳的方法。 Paraformer通过encoder之后的predictor模块实现token级别的声学表征的生成，predictor中的cif机制通过累积帧级别权重计算了每个token的持续区间与发射位置，这使得通过predictor实现与ASR任务一体化的时间戳预测（Timestamp Prediction, TP）成为了可能。本模型为Paraformer-large-长音频版的衍生模型，通过较小参数量的encoder与升采样cif predictor实现了时间戳预测功能，方便用户自由搭建ASR链路中的功能环节。

其核心点主要有：

* Upsample Predictor 模块：在低帧率模型中predictor产生的帧级别权重可能存在预测不稳定的问题，表现为首尾帧出字与连续帧出字，这为基于cif权重的时间戳预测带来了困扰。本模型
  * (1) 在predictor的线性层之前引入了反卷积升采样模块与lstm模块，在多倍帧率的情况下预测权重；
  * (2) 通过scaled cif对权重进行尺度缩小与平滑，使得cif权重不表现为一个peak而是一段累积过程。通过上述两个操作得到了能用于时间戳预测的帧权重。
* 基于约5w小时工业数据训练的时间戳预测模型，鲁棒性更强，时间戳准确率更高。

#### 基于ModelScope进行推理

* 推理支持音频格式如下：
  * wav文件路径，例如：data/test/audios/asr_example.wav
  * pcm文件路径，例如：data/test/audios/asr_example.pcm
  * wav文件url，例如：[https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_timestamps.wav](https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_timestamps.wav)
  * wav二进制数据，格式bytes，例如：用户直接从文件里读出bytes数据或者是麦克风录出bytes数据。
  * 已解析的audio音频，例如：audio, rate = soundfile.read("asr_example_zh.wav")，类型为numpy.ndarray或者torch.Tensor。
  * wav.scp文件，需符合如下要求：

<pre><div class="acss-q09o5g"><div node="[object Object]"><code class="language-sh"><span><span>cat wav.scp
</span></span><span>asr_example1  data/test/audios/asr_example1.wav
</span><span>asr_example2  data/test/audios/asr_example2.wav
</span><span>...
</span><span></span></code></div><div class="acss-1wlnmrj"><span role="img" tabindex="-1" class="anticon acss-1sra2vo acss-yiit70"><svg width="1em" height="1em" fill="currentColor" aria-hidden="true" focusable="false" class=""><use xlink:href="#icon-maasfuzhi-copy-line"></use></svg></span><div data-autolog="clk=true&exp=true&c3=notebook&c4=openNotebookDrawerFree&c5=%7B%22source%22%3A%22codeBlock%22%2C%22inNotebook%22%3Afalse%7D" autolog-exp-hash="bfbec0da3ce346" autolog-exp-reported="1"></div></div></div></pre>

* 若输入格式wav文件url，api调用方式可参考如下范例：

<pre><div class="acss-q09o5g"><div node="[object Object]"><code class="language-python"><span><span>from</span><span> modelscope.pipelines </span><span>import</span><span> pipeline
</span></span><span><span></span><span>from</span><span> modelscope.utils.constant </span><span>import</span><span> Tasks
</span></span><span>
</span><span>inference_pipline = pipeline(
</span><span>    task=Tasks.speech_timestamp,
</span><span><span>    model=</span><span>'iic/speech_timestamp_prediction-v1-16k-offline'</span><span>,
</span></span><span><span>    model_revision=</span><span>"v2.0.4"</span><span>,
</span></span><span><span>    output_dir=</span><span>'./tmp'</span><span>)
</span></span><span>
</span><span><span>wav_file = </span><span>"https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_example_timestamps.wav"</span><span>
</span></span><span><span>text_file = </span><span>"一 个 东 太 平 洋 国 家 为 什 么 跑 到 西 太 平 洋 来 了 呢"</span><span>
</span></span><span><span>rec_result = inference_pipline(</span><span>input</span><span>=(wav_file, text_file), data_type=(</span><span>"sound"</span><span>, </span><span>"text"</span><span>))
</span></span><span><span></span><span>print</span><span>(rec_result)
</span></span><span></span></code></div><div class="acss-1wlnmrj"><span role="img" tabindex="-1" class="anticon acss-1sra2vo acss-yiit70"><svg width="1em" height="1em" fill="currentColor" aria-hidden="true" focusable="false" class=""><use xlink:href="#icon-maasfuzhi-copy-line"></use></svg></span><div data-autolog="clk=true&exp=true&c3=notebook&c4=openNotebookDrawerFree&c5=%7B%22source%22%3A%22codeBlock%22%2C%22inNotebook%22%3Afalse%7D" autolog-exp-hash="f3f60e0696d245" autolog-exp-reported="1"></div></div></div></pre>

* 若输入格式为文件wav.scp与对应的抄本text.txt(注：文件名需要以.txt结尾)，可添加 output_dir 参数将识别结果写入文件中，api调用方式可参考如下范例:

<pre><div class="acss-q09o5g"><div node="[object Object]"><code class="language-python"><span><span>wav_file = </span><span>"./wav.scp"</span><span>
</span></span><span><span>text_file = </span><span>"/text.txt"</span><span>
</span></span><span><span>rec_result = inference_pipline(</span><span>input</span><span>=(wav_file, text_file), data_type=(</span><span>"sound"</span><span>, </span><span>"text"</span><span>))
</span></span><span><span></span><span>print</span><span>(rec_result)
</span></span><span></span></code></div><div class="acss-1wlnmrj"><span role="img" tabindex="-1" class="anticon acss-1sra2vo acss-yiit70"><svg width="1em" height="1em" fill="currentColor" aria-hidden="true" focusable="false" class=""><use xlink:href="#icon-maasfuzhi-copy-line"></use></svg></span><div data-autolog="clk=true&exp=true&c3=notebook&c4=openNotebookDrawerFree&c5=%7B%22source%22%3A%22codeBlock%22%2C%22inNotebook%22%3Afalse%7D" autolog-exp-hash="7463350c76914a" autolog-exp-reported="1"></div></div></div></pre>

输出的结果为带有静音标注时间戳的字符串以及排除了静音标注的与token数量一致的时间戳列表：

'text': ' 0.000 0.380;一 0.380 0.560;个 0.560 0.800;东 0.800 0.980;太 0.980 1.140;平 1.140 1.260;洋 1.260 1.440;国 1.440 1.680;家 1.680 1.920; 1.920 2.040;为 2.040 2.200;什 2.200 2.320;么 2.320 2.500;跑 2.500 2.680;到 2.680 2.880;西 2.880 3.060;太 3.060 3.200;平 3.200 3.380;洋 3.380 3.500;来 3.500 3.660;了 3.660 3.800;呢 3.800 4.160; 4.160 4.440;',

'timestamp': [[380, 560], [560, 800], [800, 980], [980, 1140], [1140, 1260], [1260, 1440], [1440, 1680], [1680, 1920], [2040, 2200], [2200, 2320], [2320, 2500], [2500, 2680], [2680, 2880], [2880, 3060], [3060, 3200], [3200, 3380], [3380, 3500], [3500, 3660], [3660, 3800], [3800, 4160]]

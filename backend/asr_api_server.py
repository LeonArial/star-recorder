"""
è¯­éŸ³è¯†åˆ«APIæœåŠ¡å™¨
æä¾›RESTful APIæ¥å£è¿›è¡ŒéŸ³é¢‘è½¬å½•
æ”¯æŒä¸‰ç§è¯†åˆ«ç»“æœå¯¹æ¯”ï¼šParaformer + SenseVoice + LLMæ™ºèƒ½åˆå¹¶
"""
import os
import tempfile
import wave
import json
import numpy as np
from flask import Flask, request, jsonify
from flask_socketio import SocketIO, emit
from flask_cors import CORS
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess
import soundfile as sf
import librosa
import requests
import re
import traceback

app = Flask(__name__)
app.config['SECRET_KEY'] = 'asr-api-server'
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# SocketIO é…ç½®ï¼ˆä¼˜åŒ–é•¿æ—¶é—´å½•éŸ³ç¨³å®šæ€§ï¼‰
socketio = SocketIO(
    app, 
    cors_allowed_origins="*", 
    async_mode='threading',
    # å¢åŠ  ping è¶…æ—¶æ—¶é—´ï¼ˆé»˜è®¤20ç§’å¤ªçŸ­ï¼Œé•¿æ—¶é—´å½•éŸ³å¯èƒ½è¶…æ—¶ï¼‰
    ping_timeout=120,  # 120ç§’è¶…æ—¶
    ping_interval=30,  # æ¯30ç§’å‘é€ä¸€æ¬¡ping
    # å¢åŠ æœ€å¤§ç¼“å†²åŒºå¤§å°ï¼ˆæ”¯æŒæ›´å¤§çš„éŸ³é¢‘æ•°æ®å¸§ï¼‰
    max_http_buffer_size=10 * 1024 * 1024,  # 10MB
)

# å…¨å±€æ¨¡å‹å®ä¾‹
asr_model = None
punc_model = None
punc_realtime_model = None  # å®æ—¶æ ‡ç‚¹æ¨¡å‹
vad_model = None  # VADè¯­éŸ³ç«¯ç‚¹æ£€æµ‹æ¨¡å‹
sensevoice_model = None
timestamp_model = None  # æ—¶é—´æˆ³é¢„æµ‹æ¨¡å‹

# LLMé…ç½®
LLM_API_URL = "http://10.8.75.207:9997/v1/chat/completions"
LLM_API_KEY = "sk-dmowsenrtifmlnpmlhaatxgkxnhbmusjfzgnofvlhtblslwa"
LLM_MODEL = "qwen3:8b"

# æ”¯æŒçš„éŸ³é¢‘æ ¼å¼
ALLOWED_EXTENSIONS = {'wav', 'mp3', 'ogg', 'flac', 'm4a', 'aac', 'wma'}

# çƒ­è¯é…ç½®æ–‡ä»¶è·¯å¾„
HOTWORDS_FILE = os.path.join(os.path.dirname(__file__), 'hotwords.json')

# æ¨¡å‹ç¼“å­˜ç›®å½•ï¼ˆDockeræŒ‚è½½æˆ–æœ¬åœ°ç›®å½•ï¼‰
# ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œå…¶æ¬¡ä½¿ç”¨é¡¹ç›®ç›®å½•ä¸‹çš„ models_cache
MODELS_CACHE_DIR = os.environ.get('MODELSCOPE_CACHE', 
    os.path.join(os.path.dirname(__file__), 'models_cache'))
HF_CACHE_DIR = os.environ.get('HF_HOME',
    os.path.join(os.path.dirname(__file__), 'hf_cache'))

# çƒ­è¯ç¼“å­˜
hotwords_cache = []

# å­˜å‚¨å®æ—¶å½•éŸ³ä¼šè¯
active_sessions = {}


def init_models():
    """åˆå§‹åŒ– ASRã€æ ‡ç‚¹ã€VADä¸å¤æ£€æ¨¡å‹
    
    æ¨¡å‹ç¼“å­˜ç­–ç•¥ï¼š
    - ä¼˜å…ˆä» MODELSCOPE_CACHE ç›®å½•åŠ è½½å·²æœ‰æ¨¡å‹
    - å¦‚æœæ¨¡å‹ä¸å­˜åœ¨åˆ™è‡ªåŠ¨ä¸‹è½½åˆ°ç¼“å­˜ç›®å½•
    - Dockerè¿è¡Œæ—¶é€šè¿‡æŒ‚è½½å·æŒä¹…åŒ–æ¨¡å‹ï¼Œé¿å…é‡å¤ä¸‹è½½
    """
    global asr_model, punc_model, punc_realtime_model, vad_model, sensevoice_model, timestamp_model
    
    if asr_model is None:
        print("ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹...")
        
        # è®¾ç½®æ¨¡å‹ç¼“å­˜ç¯å¢ƒå˜é‡ï¼ˆç¡®ä¿FunASRä½¿ç”¨æ­£ç¡®çš„ç¼“å­˜è·¯å¾„ï¼‰
        os.environ['MODELSCOPE_CACHE'] = MODELS_CACHE_DIR
        os.environ['HF_HOME'] = HF_CACHE_DIR
        
        # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
        os.makedirs(MODELS_CACHE_DIR, exist_ok=True)
        os.makedirs(HF_CACHE_DIR, exist_ok=True)
        
        print(f"ğŸ“ æ¨¡å‹ç¼“å­˜ç›®å½•: {MODELS_CACHE_DIR}")
        print(f"ğŸ“ HuggingFaceç¼“å­˜ç›®å½•: {HF_CACHE_DIR}")
        
        # æ£€æµ‹è®¾å¤‡ï¼ˆCUDA GPU > Apple MPS > CPUï¼‰
        try:
            import torch
            if torch.cuda.is_available():
                # NVIDIA GPUï¼ˆLinux/Windows æœåŠ¡å™¨ï¼‰
                device = "cuda:0"
                print(f"âœ… æ£€æµ‹åˆ° CUDA GPU: {torch.cuda.get_device_name(0)}")
            elif torch.backends.mps.is_available() and torch.backends.mps.is_built():
                # Apple Silicon MPSï¼ˆM1/M2/M3/M4 Macï¼‰
                device = "mps"
                print("âœ… æ£€æµ‹åˆ° Apple Siliconï¼Œä½¿ç”¨ MPS åŠ é€Ÿ")
            else:
                device = "cpu"
                print("âš ï¸ æœªæ£€æµ‹åˆ° GPUï¼Œä½¿ç”¨ CPU æ¨¡å¼ï¼ˆæ€§èƒ½è¾ƒä½ï¼‰")
        except Exception as e:
            device = "cpu"
            print(f"âš ï¸ è®¾å¤‡æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨ CPU æ¨¡å¼: {e}")
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ç¼“å­˜
        def check_model_cached(model_name):
            """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åœ¨ç¼“å­˜ä¸­"""
            # ModelScopeæ¨¡å‹é€šå¸¸ç¼“å­˜åœ¨ hub/æ¨¡å‹å ç›®å½•ä¸‹
            model_path = os.path.join(MODELS_CACHE_DIR, 'hub', model_name.replace('/', '--'))
            if os.path.exists(model_path):
                return True
            # ä¹Ÿæ£€æŸ¥ç›´æ¥çš„æ¨¡å‹åç›®å½•
            model_path_alt = os.path.join(MODELS_CACHE_DIR, 'hub', model_name)
            return os.path.exists(model_path_alt)
        
        # åŠ è½½ä¸­æ–‡æµå¼ ASR æ¨¡å‹
        model_name = "paraformer-zh-streaming"
        cached = "(å·²ç¼“å­˜)" if check_model_cached(f"iic/{model_name}") else "(é¦–æ¬¡ä¸‹è½½)"
        print(f"  - åŠ è½½ ASR æ¨¡å‹: {model_name} {cached} (è®¾å¤‡: {device})")
        asr_model = AutoModel(
            model=model_name,
            device=device,
            disable_update=True,
        )
        
        # åŠ è½½æ ‡ç‚¹æ¢å¤æ¨¡å‹ï¼ˆç¦»çº¿ï¼Œç”¨äºæœ€ç»ˆç»“æœï¼‰
        model_name = "ct-punc"
        cached = "(å·²ç¼“å­˜)" if check_model_cached(f"iic/{model_name}") else "(é¦–æ¬¡ä¸‹è½½)"
        print(f"  - åŠ è½½æ ‡ç‚¹æ¨¡å‹: {model_name} {cached} (è®¾å¤‡: {device})")
        punc_model = AutoModel(
            model=model_name,
            device=device,
            disable_update=True,
        )
        
        # åŠ è½½å®æ—¶æ ‡ç‚¹æ¨¡å‹ï¼ˆæ”¯æŒæµå¼å¤„ç†ï¼Œå¸¦ç¼“å­˜ï¼‰
        model_name = "iic/punc_ct-transformer_zh-cn-common-vad_realtime-vocab272727"
        cached = "(å·²ç¼“å­˜)" if check_model_cached(model_name) else "(é¦–æ¬¡ä¸‹è½½)"
        print(f"  - åŠ è½½å®æ—¶æ ‡ç‚¹æ¨¡å‹: punc_realtime {cached} (è®¾å¤‡: {device})")
        punc_realtime_model = AutoModel(
            model=model_name,
            device=device,
            disable_update=True,
        )
        
        # åŠ è½½VADè¯­éŸ³ç«¯ç‚¹æ£€æµ‹æ¨¡å‹ï¼ˆå®æ—¶ï¼‰
        model_name = "fsmn-vad"
        cached = "(å·²ç¼“å­˜)" if check_model_cached(f"iic/{model_name}") else "(é¦–æ¬¡ä¸‹è½½)"
        print(f"  - åŠ è½½VADæ¨¡å‹: {model_name} {cached} (è®¾å¤‡: {device})")
        vad_model = AutoModel(
            model=model_name,
            device=device,
            disable_update=True,
        )
        
        # SenseVoice å¤æ£€æ¨¡å‹ï¼ˆé…ç½®VADï¼‰
        model_name = "iic/SenseVoiceSmall"
        cached = "(å·²ç¼“å­˜)" if check_model_cached(model_name) else "(é¦–æ¬¡ä¸‹è½½)"
        print(f"  - åŠ è½½å¤æ£€æ¨¡å‹: SenseVoiceSmall {cached} (è®¾å¤‡: {device})")
        sensevoice_model = AutoModel(
            model=model_name,
            vad_model="fsmn-vad",
            vad_kwargs={"max_single_segment_time": 30000},
            device=device,
            disable_update=True,
            use_itn=True,
        )
        
        # æ—¶é—´æˆ³é¢„æµ‹æ¨¡å‹ï¼ˆç”¨äºç”Ÿæˆå­—çº§æ—¶é—´æˆ³ï¼‰
        model_name = "fa-zh"
        cached = "(å·²ç¼“å­˜)" if check_model_cached(f"iic/{model_name}") else "(é¦–æ¬¡ä¸‹è½½)"
        print(f"  - åŠ è½½æ—¶é—´æˆ³æ¨¡å‹: {model_name} {cached} (è®¾å¤‡: {device})")
        timestamp_model = AutoModel(
            model=model_name,
            device=device,
            disable_update=True,
        )
        
        print("âœ… æ‰€æœ‰æ¨¡å‹åŠ è½½å®Œæˆï¼")


def load_hotwords():
    """ä»JSONæ–‡ä»¶åŠ è½½çƒ­è¯åˆ—è¡¨"""
    global hotwords_cache
    
    try:
        if os.path.exists(HOTWORDS_FILE):
            with open(HOTWORDS_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                hotwords_cache = data.get('hotwords', [])
                print(f"ğŸ“ å·²åŠ è½½ {len(hotwords_cache)} ä¸ªçƒ­è¯")
                return hotwords_cache
        else:
            print(f"âš ï¸ çƒ­è¯æ–‡ä»¶ä¸å­˜åœ¨: {HOTWORDS_FILE}")
            hotwords_cache = []
            return []
    except Exception as e:
        print(f"âŒ åŠ è½½çƒ­è¯å¤±è´¥: {str(e)}")
        hotwords_cache = []
        return []


def reload_hotwords():
    """é‡æ–°åŠ è½½çƒ­è¯ï¼ˆå¯ç”¨äºè¿è¡Œæ—¶æ›´æ–°çƒ­è¯ï¼‰"""
    return load_hotwords()


def allowed_file(filename):
    """æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


def _run_paraformer(audio_path):
    """ä½¿ç”¨Paraformerè¿›è¡Œå®Œæ•´éŸ³é¢‘è¯†åˆ«"""
    try:
        # è¯»å–å·²è½¬æ¢çš„WAVéŸ³é¢‘æ–‡ä»¶ï¼ˆ16kHz, å•å£°é“ï¼‰
        audio, sample_rate = sf.read(audio_path)
        
        # Paraformerè¯†åˆ«
        result = asr_model.generate(
            input=audio,
            cache={},
            is_final=True,
            chunk_size=[0, 10, 5],
        )
        
        raw_text = ""
        if result and len(result) > 0:
            raw_text = result[0].get("text", "")
        
        # æ ‡ç‚¹æ¢å¤
        if raw_text and punc_model:
            punc_result = punc_model.generate(input=raw_text)
            if punc_result and len(punc_result) > 0:
                return punc_result[0]["text"]
        
        return raw_text
        
    except Exception as e:
        raise Exception(f"Paraformerè¯†åˆ«å¤±è´¥: {str(e)}")


def _run_sensevoice(audio_path):
    """ä½¿ç”¨SenseVoiceè¿›è¡Œå®Œæ•´éŸ³é¢‘è¯†åˆ«ï¼ˆæ–‡ä»¶è·¯å¾„ï¼‰"""
    try:
        result = sensevoice_model.generate(
            input=audio_path,
            cache={},
            language="auto",
            use_itn=True,
            batch_size_s=60,
            merge_vad=True,
            merge_length_s=15,  # åˆå¹¶åçš„éŸ³é¢‘ç‰‡æ®µé•¿åº¦
        )
        
        if result and len(result) > 0:
            raw_text = result[0].get("text", "")
            # ä½¿ç”¨å®˜æ–¹çš„å¯Œæ–‡æœ¬åå¤„ç†å‡½æ•°æ¸…ç†ç‰¹æ®Šæ ‡è®°
            clean_text = rich_transcription_postprocess(raw_text)
            return clean_text
        
        return ""
        
    except Exception as e:
        raise Exception(f"SenseVoiceè¯†åˆ«å¤±è´¥: {str(e)}")


def _run_sensevoice_array(audio_array, sample_rate):
    """ä½¿ç”¨SenseVoiceè¿›è¡Œå®Œæ•´éŸ³é¢‘è¯†åˆ«ï¼ˆnumpyæ•°ç»„ï¼‰"""
    try:
        # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
        temp_path = temp_file.name
        temp_file.close()
        
        sf.write(temp_path, audio_array, sample_rate)
        
        result = sensevoice_model.generate(
            input=temp_path,
            cache={},
            language="auto",
            use_itn=True,
            batch_size_s=60,
            merge_vad=True,
            merge_length_s=15,  # åˆå¹¶åçš„éŸ³é¢‘ç‰‡æ®µé•¿åº¦
        )
        
        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        os.remove(temp_path)
        
        if result and len(result) > 0:
            raw_text = result[0].get("text", "")
            clean_text = rich_transcription_postprocess(raw_text)
            return clean_text
        
        return ""
        
    except Exception as e:
        raise Exception(f"SenseVoiceè¯†åˆ«å¤±è´¥: {str(e)}")


def _generate_timestamps(audio_array, sample_rate, text):
    """ä½¿ç”¨ fa-zh æ¨¡å‹ç”Ÿæˆç²¾ç¡®çš„å­—çº§æ—¶é—´æˆ³
    
    Args:
        audio_array: numpy float32 éŸ³é¢‘æ•°ç»„
        sample_rate: é‡‡æ ·ç‡
        text: è¦å¯¹é½çš„æ–‡æœ¬
    
    Returns:
        list: æ—¶é—´æˆ³åˆ—è¡¨ [{'char': 'å­—', 'start_ms': 0, 'end_ms': 100}, ...]
    """
    if not timestamp_model or not text:
        return []
    
    try:
        # ä¿å­˜éŸ³é¢‘ä¸ºä¸´æ—¶æ–‡ä»¶
        temp_audio = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
        temp_audio_path = temp_audio.name
        temp_audio.close()
        sf.write(temp_audio_path, audio_array, sample_rate)
        
        # ä¿å­˜æ–‡æœ¬ä¸ºä¸´æ—¶æ–‡ä»¶
        temp_text = tempfile.NamedTemporaryFile(delete=False, suffix='.txt', mode='w', encoding='utf-8')
        temp_text_path = temp_text.name
        # ç§»é™¤æ ‡ç‚¹ç¬¦å·ï¼Œåªä¿ç•™æ–‡å­—ï¼ˆfa-zh æ¨¡å‹éœ€è¦çº¯æ–‡æœ¬ï¼‰
        clean_text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9]', '', text)
        temp_text.write(clean_text)
        temp_text.close()
        
        # è°ƒç”¨æ—¶é—´æˆ³æ¨¡å‹
        result = timestamp_model.generate(
            input=(temp_audio_path, temp_text_path),
            data_type=("sound", "text")
        )
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        os.remove(temp_audio_path)
        os.remove(temp_text_path)
        
        if not result or len(result) == 0:
            return []
        
        # è§£ææ—¶é—´æˆ³ç»“æœ
        # fa-zh è¾“å‡ºæ ¼å¼: [{'text': 'å­—', 'timestamp': [[start_s, end_s], ...]}]
        timestamps = []
        raw_result = result[0]
        
        if 'timestamp' in raw_result:
            # fa-zh è¾“å‡ºæ ¼å¼: timestamp å·²ç»æ˜¯æ¯«ç§’çº§ [[380, 560], [560, 800], ...]
            chars = list(clean_text)
            ts_list = raw_result['timestamp']
            for i, ts in enumerate(ts_list):
                if i < len(chars) and len(ts) >= 2:
                    timestamps.append({
                        'char': chars[i],
                        'start_ms': int(ts[0]),  # å·²ç»æ˜¯æ¯«ç§’ï¼Œä¸éœ€è¦ * 1000
                        'end_ms': int(ts[1])
                    })
        elif 'value' in raw_result:
            # å…¶ä»–å¯èƒ½çš„æ ¼å¼
            for item in raw_result['value']:
                if isinstance(item, dict) and 'text' in item:
                    timestamps.append({
                        'char': item.get('text', ''),
                        'start_ms': int(item.get('start', 0) * 1000),
                        'end_ms': int(item.get('end', 0) * 1000)
                    })
        
        # å°†å­—çº§æ—¶é—´æˆ³èšåˆä¸ºè¯/å¥çº§æ—¶é—´æˆ³ï¼ˆä¾¿äºå‰ç«¯æ˜¾ç¤ºï¼‰
        segments = _aggregate_timestamps(timestamps, text)
        
        return segments
        
    except Exception as e:
        print(f"âš ï¸ æ—¶é—´æˆ³ç”Ÿæˆé”™è¯¯: {str(e)}")
        traceback.print_exc()
        return []


def _aggregate_timestamps(char_timestamps, original_text):
    """å°†å­—çº§æ—¶é—´æˆ³èšåˆä¸ºå¥çº§æ—¶é—´æˆ³
    
    æ ¹æ®åŸæ–‡ä¸­çš„æ ‡ç‚¹ç¬¦å·è¿›è¡Œåˆ†å¥ï¼Œæ¯å¥è¯å¯¹åº”ä¸€ä¸ªæ—¶é—´æ®µ
    """
    if not char_timestamps:
        return []
    
    segments = []
    current_segment = {
        'text': '',
        'start_ms': char_timestamps[0]['start_ms'] if char_timestamps else 0,
        'end_ms': 0,
        'chars': []  # ä¿ç•™å­—çº§æ—¶é—´æˆ³ä¾›ç²¾ç¡®å®šä½
    }
    
    char_idx = 0
    for char in original_text:
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡ç‚¹ç¬¦å·ï¼ˆç”¨äºåˆ†å¥ï¼‰
        is_punctuation = char in 'ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€,!?;:'
        is_sentence_end = char in 'ã€‚ï¼ï¼Ÿ!?'
        
        if re.match(r'[\u4e00-\u9fa5a-zA-Z0-9]', char):
            # æ˜¯æ–‡å­—å­—ç¬¦ï¼Œæ·»åŠ åˆ°å½“å‰ç‰‡æ®µ
            current_segment['text'] += char
            if char_idx < len(char_timestamps):
                current_segment['chars'].append(char_timestamps[char_idx])
                current_segment['end_ms'] = char_timestamps[char_idx]['end_ms']
                char_idx += 1
        elif is_punctuation:
            # æ˜¯æ ‡ç‚¹ç¬¦å·ï¼Œæ·»åŠ åˆ°æ–‡æœ¬ä½†ä¸å½±å“æ—¶é—´æˆ³
            current_segment['text'] += char
            
            # å¦‚æœæ˜¯å¥æœ«æ ‡ç‚¹ï¼Œç»“æŸå½“å‰ç‰‡æ®µ
            if is_sentence_end and current_segment['text'].strip():
                segments.append(current_segment)
                # å¼€å§‹æ–°ç‰‡æ®µ
                next_start = current_segment['end_ms']
                if char_idx < len(char_timestamps):
                    next_start = char_timestamps[char_idx]['start_ms']
                current_segment = {
                    'text': '',
                    'start_ms': next_start,
                    'end_ms': next_start,
                    'chars': []
                }
    
    # æ·»åŠ æœ€åä¸€ä¸ªç‰‡æ®µ
    if current_segment['text'].strip():
        segments.append(current_segment)
    
    return segments


def _call_llm_merge(paraformer_text, sensevoice_text):
    """è°ƒç”¨LLMå¯¹ä¸¤ä¸ªè¯†åˆ«ç»“æœè¿›è¡Œæ£€æŸ¥ã€çº é”™ã€åˆå¹¶"""
    
    # æ„å»ºç³»ç»Ÿæç¤ºè¯
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¯­éŸ³è¯†åˆ«ç»“æœæ ¡å¯¹åŠ©æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯ï¼š
    1. **å¯¹æ¯”åˆ†æ**ï¼šå¯¹æ¯”ä¸¤ä¸ªè¯­éŸ³è¯†åˆ«æ¨¡å‹çš„è¾“å‡ºç»“æœ
    - Paraformerï¼šå®æ—¶æµå¼è¯†åˆ«ç»“æœï¼Œé€Ÿåº¦å¿«ä½†å‡†ç¡®åº¦ç›¸å¯¹è¾ƒä½ï¼Œå¯èƒ½å­˜åœ¨è¾ƒå¤šé”™è¯¯
    - SenseVoiceï¼šå®Œæ•´éŸ³é¢‘è¯†åˆ«ç»“æœï¼Œå‡†ç¡®åº¦é«˜ï¼Œè´¨é‡æ›´å¯é 

    2. **çº é”™åˆå¹¶ç­–ç•¥**ï¼š
    - ä¼˜å…ˆé‡‡ç”¨SenseVoiceçš„ç»“æœï¼Œå®ƒçš„å‡†ç¡®åº¦æ˜æ˜¾é«˜äºParaformer
    - åœ¨SenseVoiceæ˜æ˜¾æœ‰ä¸åˆç†çš„æƒ…å†µä¸‹ï¼Œå‚è€ƒParaformerè¿›è¡Œè¡¥å……
    - è¯†åˆ«å¹¶çº æ­£è¯†åˆ«é”™è¯¯ï¼ˆåŒéŸ³å­—ã€å¤šå­—ã€å°‘å­—ã€é”™åˆ«å­—ã€æ ‡ç‚¹ç¬¦å·ç­‰ï¼‰
    - ä¿æŒè¯­å¥é€šé¡ºã€è¯­ä¹‰è¿è´¯

    3. **è¾“å‡ºè¦æ±‚**ï¼š
    - åªè¾“å‡ºæœ€ç»ˆçº æ­£åçš„æ–‡æœ¬ï¼Œä¸è¦ä»»ä½•è§£é‡Šè¯´æ˜
    - ä¸è¦æ·»åŠ ä¸å­˜åœ¨çš„å†…å®¹"""

    # ä»å…¨å±€ç¼“å­˜è¯»å–çƒ­è¯å¹¶æ·»åŠ åˆ°æç¤ºè¯ä¸­
    if hotwords_cache and len(hotwords_cache) > 0:
        hotword_list = "ã€".join(hotwords_cache)
        system_prompt += f"\n4. **è‡ªå®šä¹‰è¯åŒ¹é…æ›¿æ¢**ï¼ˆä¼˜å…ˆä½¿ç”¨ä»¥ä¸‹è‡ªå®šä¹‰è¯æ›¿æ¢è¯†åˆ«ç»“æœä¸­çš„å¯èƒ½é”™è¯¯çš„è¯ï¼‰ï¼š\n{hotword_list}"
    
    # æ„å»ºç”¨æˆ·è¾“å…¥
    user_content = f"""è¯·æ£€æŸ¥ã€çº é”™å¹¶åˆå¹¶ä»¥ä¸‹ä¸¤ä¸ªè¯­éŸ³è¯†åˆ«ç»“æœï¼š
    **Paraformerè¯†åˆ«ç»“æœ**ï¼š
    {paraformer_text}

    **SenseVoiceè¯†åˆ«ç»“æœ**ï¼š
    {sensevoice_text}

    è¯·è¾“å‡ºçº æ­£åçš„æœ€ç»ˆæ–‡æœ¬ï¼š"""
    
    try:
        headers = {
            'Content-Type': 'application/json',
            'Authorization': f'Bearer {LLM_API_KEY}'
        }
        
        data = {
            "model": LLM_MODEL,
            "messages": [
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": user_content
                }
            ],
            "temperature": 0.3
        }
        
        print(f"ğŸ¤– æ­£åœ¨è°ƒç”¨LLMåˆå¹¶ç»“æœ...")
        response = requests.post(LLM_API_URL, headers=headers, json=data, timeout=30)
        result = response.json()
        
        if "choices" in result and len(result["choices"]) > 0:
            merged_text = result["choices"][0]["message"]["content"].strip()
            
            # è¿‡æ»¤æ‰ <think> æ ‡ç­¾åŠå…¶å†…å®¹
            think_pattern = r"<think>.*?</think>"
            merged_text = re.sub(think_pattern, "", merged_text, flags=re.DOTALL).strip()
            
            print(f"âœ… LLMåˆå¹¶å®Œæˆ")
            return merged_text
        else:
            raise Exception(f"LLMå“åº”æ ¼å¼é”™è¯¯: {result}")
            
    except Exception as e:
        error_msg = f"LLMè°ƒç”¨å¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}")
        # å¦‚æœLLMå¤±è´¥ï¼Œè¿”å›SenseVoiceç»“æœä½œä¸ºåå¤‡
        return sensevoice_text if sensevoice_text else paraformer_text


# ==================== å®æ—¶å½•éŸ³å¤„ç†ç±» ====================

class RealtimeASR:
    """å®æ—¶è¯­éŸ³è¯†åˆ«å¤„ç†å™¨
    
    ä¼˜åŒ–ç‰¹æ€§ï¼š
    - ä½¿ç”¨ fsmn-vad è¿›è¡Œå®æ—¶è¯­éŸ³ç«¯ç‚¹æ£€æµ‹
    - ä½¿ç”¨å®æ—¶æ ‡ç‚¹æ¨¡å‹è¿›è¡Œæµå¼æ ‡ç‚¹æ¢å¤
    - åŸºäº VAD ç»“æœæ™ºèƒ½åˆ†å¥ï¼Œæå‡è¯†åˆ«ä½“éªŒ
    """
    
    def __init__(self, session_id):
        self.session_id = session_id
        self.sample_rate = 16000
        
        # ASR ç›¸å…³é…ç½®
        self.audio_buffer = []  # ASR éŸ³é¢‘ç¼“å†²åŒº
        self.asr_cache = {}  # æµå¼ ASR è¯†åˆ«ç¼“å­˜
        self.chunk_size = [0, 10, 5]  # [0, 10, 5] è¡¨ç¤º 600ms å®æ—¶å‡ºå­—
        self.asr_chunk_stride = self.chunk_size[1] * 960  # 600ms = 9600 é‡‡æ ·ç‚¹
        
        # VAD ç›¸å…³é…ç½®
        self.vad_buffer = []  # VAD éŸ³é¢‘ç¼“å†²åŒº
        self.vad_cache = {}  # VAD æ£€æµ‹ç¼“å­˜
        self.vad_chunk_size = 200  # VAD æ£€æµ‹ç²’åº¦ 200ms
        self.vad_chunk_stride = int(self.vad_chunk_size * self.sample_rate / 1000)  # 3200 é‡‡æ ·ç‚¹
        self.is_speech_active = False  # å½“å‰æ˜¯å¦æ£€æµ‹åˆ°è¯­éŸ³
        self.speech_start_time = 0  # è¯­éŸ³å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        self.total_audio_ms = 0  # å·²å¤„ç†çš„éŸ³é¢‘æ€»æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
        
        # æ ‡ç‚¹ç›¸å…³é…ç½®
        self.punc_cache = {}  # å®æ—¶æ ‡ç‚¹ç¼“å­˜
        self.all_text = ""  # ç´¯ç§¯æ‰€æœ‰è¯†åˆ«æ–‡æœ¬ï¼ˆæ— æ ‡ç‚¹ï¼‰
        self.text_with_punc = ""  # å·²æ·»åŠ æ ‡ç‚¹çš„æ–‡æœ¬
        self.pending_text = ""  # ç­‰å¾…æ ‡ç‚¹çš„æ–‡æœ¬
        self.sentence_buffer = ""  # å½“å‰å¥å­ç¼“å†²åŒºï¼ˆVAD åˆ†å¥ç”¨ï¼‰
        
        # å®Œæ•´å½•éŸ³ç¼“å­˜ï¼ˆç”¨äº SenseVoice æœ€ç»ˆè¯†åˆ«ï¼‰
        self.full_audio = []
        
        # å®æ—¶æ—¶é—´æˆ³è·Ÿè¸ª
        self.asr_processed_ms = 0  # ASR å·²å¤„ç†çš„éŸ³é¢‘æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰
        self.segments = []  # å¸¦æ—¶é—´æˆ³çš„æ–‡æœ¬ç‰‡æ®µåˆ—è¡¨ [{text, start_ms, end_ms}, ...]
        self.current_segment_start = 0  # å½“å‰ç‰‡æ®µèµ·å§‹æ—¶é—´
        
    def add_audio(self, audio_data):
        """æ·»åŠ éŸ³é¢‘æ•°æ®åˆ°ç¼“å†²åŒº"""
        try:
            # ç¡®ä¿æ•°æ®é•¿åº¦æ˜¯ 2 çš„å€æ•°ï¼ˆint16 = 2 bytesï¼‰
            if len(audio_data) % 2 != 0:
                audio_data = audio_data[:-1]
            
            if len(audio_data) == 0:
                return
            
            # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸º float32 numpy æ•°ç»„
            audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0
            self.audio_buffer.extend(audio_np)
            self.vad_buffer.extend(audio_np)
            self.full_audio.extend(audio_np)  # ä¿å­˜å®Œæ•´éŸ³é¢‘ç”¨äº SenseVoice
        except Exception as e:
            print(f"âŒ éŸ³é¢‘æ•°æ®å¤„ç†é”™è¯¯: {str(e)}")
    
    def _process_vad(self):
        """å¤„ç† VAD è¯­éŸ³ç«¯ç‚¹æ£€æµ‹
        
        è¿”å›å€¼ï¼š
        - None: æ²¡æœ‰æ£€æµ‹åˆ°ç«¯ç‚¹å˜åŒ–
        - {'type': 'start', 'time': ms}: æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹
        - {'type': 'end', 'time': ms}: æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ
        """
        if len(self.vad_buffer) < self.vad_chunk_stride:
            return None
        
        try:
            # å–å‡º VAD chunk
            vad_chunk = np.array(self.vad_buffer[:self.vad_chunk_stride], dtype=np.float32)
            self.vad_buffer = self.vad_buffer[self.vad_chunk_stride:]
            
            # VAD æ£€æµ‹
            is_final = False
            vad_result = vad_model.generate(
                input=vad_chunk,
                cache=self.vad_cache,
                is_final=is_final,
                chunk_size=self.vad_chunk_size
            )
            
            self.total_audio_ms += self.vad_chunk_size
            
            if vad_result and len(vad_result) > 0:
                segments = vad_result[0].get("value", [])
                
                # è§£æ VAD è¾“å‡º
                # [[beg, end]]: å®Œæ•´è¯­éŸ³æ®µ
                # [[beg, -1]]: åªæ£€æµ‹åˆ°èµ·å§‹ç‚¹
                # [[-1, end]]: åªæ£€æµ‹åˆ°ç»“æŸç‚¹
                # []: æ— æ£€æµ‹
                
                for seg in segments:
                    if len(seg) >= 2:
                        beg, end = seg[0], seg[1]
                        
                        if beg >= 0 and end == -1:
                            # æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹
                            if not self.is_speech_active:
                                self.is_speech_active = True
                                self.speech_start_time = beg
                                return {'type': 'start', 'time': beg}
                        
                        elif beg == -1 and end >= 0:
                            # æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸ
                            if self.is_speech_active:
                                self.is_speech_active = False
                                return {'type': 'end', 'time': end}
                        
                        elif beg >= 0 and end >= 0:
                            # å®Œæ•´è¯­éŸ³æ®µï¼ˆå¼€å§‹å’Œç»“æŸï¼‰
                            return {'type': 'segment', 'start': beg, 'end': end}
            
            return None
            
        except Exception as e:
            print(f"âš ï¸ VAD æ£€æµ‹é”™è¯¯: {str(e)}")
            return None
    
    def _apply_realtime_punc(self, text):
        """ä½¿ç”¨å®æ—¶æ ‡ç‚¹æ¨¡å‹æ·»åŠ æ ‡ç‚¹
        
        å®æ—¶æ ‡ç‚¹æ¨¡å‹æ”¯æŒæµå¼å¤„ç†ï¼Œä¼šæ ¹æ®ä¸Šä¸‹æ–‡æ™ºèƒ½æ·»åŠ æ ‡ç‚¹
        """
        if not text or not punc_realtime_model:
            return text
        
        try:
            punc_result = punc_realtime_model.generate(
                input=text,
                cache=self.punc_cache
            )
            if punc_result and len(punc_result) > 0:
                return punc_result[0].get("text", text)
        except Exception as e:
            print(f"âš ï¸ å®æ—¶æ ‡ç‚¹æ¢å¤å¤±è´¥: {str(e)}")
        
        return text
        
    def process_audio(self):
        """å¤„ç†ç¼“å†²åŒºä¸­çš„éŸ³é¢‘ï¼ˆæµå¼ï¼‰
        
        ä¼˜åŒ–é€»è¾‘ï¼š
        1. å…ˆè¿›è¡Œ VAD æ£€æµ‹ï¼Œè·å–è¯­éŸ³ç«¯ç‚¹ä¿¡æ¯
        2. è¿›è¡Œæµå¼ ASR è¯†åˆ«
        3. ä½¿ç”¨å®æ—¶æ ‡ç‚¹æ¨¡å‹æ·»åŠ æ ‡ç‚¹
        4. å½“ VAD æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸæ—¶ï¼Œå¼ºåˆ¶è¾“å‡ºå½“å‰å¥å­
        """
        # å…ˆå¤„ç† VAD
        vad_event = self._process_vad()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„éŸ³é¢‘æ•°æ®è¿›è¡Œ ASRï¼ˆ600msï¼‰
        if len(self.audio_buffer) < self.asr_chunk_stride:
            # å¦‚æœæœ‰ VAD äº‹ä»¶ä½†æ²¡æœ‰è¶³å¤ŸéŸ³é¢‘ï¼Œè¿”å› VAD çŠ¶æ€
            if vad_event:
                return {
                    "text": "",
                    "punc_text": "",
                    "full_text": self.text_with_punc + self.pending_text,
                    "is_final": False,
                    "vad_event": vad_event
                }
            return None
        
        try:
            # å–å‡ºä¸€ä¸ª chunk çš„éŸ³é¢‘
            speech_chunk = np.array(self.audio_buffer[:self.asr_chunk_stride], dtype=np.float32)
            self.audio_buffer = self.audio_buffer[self.asr_chunk_stride:]
            
            # è®°å½•å½“å‰ chunk çš„æ—¶é—´èŒƒå›´
            chunk_start_ms = self.asr_processed_ms
            chunk_end_ms = chunk_start_ms + 600  # æ¯ä¸ª chunk 600ms
            self.asr_processed_ms = chunk_end_ms
            
            # æµå¼ ASR è¯†åˆ«
            asr_result = asr_model.generate(
                input=speech_chunk,
                cache=self.asr_cache,
                is_final=False,
                chunk_size=self.chunk_size,
                encoder_chunk_look_back=4,
                decoder_chunk_look_back=1,
            )
            
            text = ""
            punc_text = ""
            current_segment = None
            
            if asr_result and len(asr_result) > 0:
                text = asr_result[0].get("text", "")
                
                if text:
                    # ç´¯ç§¯åŸå§‹æ–‡æœ¬
                    self.all_text += text
                    self.pending_text += text
                    self.sentence_buffer += text
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦è¿›è¡Œæ ‡ç‚¹å¤„ç†
                    # æ¡ä»¶ï¼šVAD æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸï¼Œæˆ–ç´¯ç§¯æ–‡æœ¬è¶…è¿‡é˜ˆå€¼
                    should_apply_punc = False
                    
                    if vad_event and vad_event.get('type') == 'end':
                        # VAD æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸï¼Œå¼ºåˆ¶å¤„ç†å½“å‰å¥å­
                        should_apply_punc = True
                    elif len(self.pending_text) >= 20:
                        # ç´¯ç§¯è¶…è¿‡ 20 å­—ç¬¦æ—¶å¤„ç†
                        should_apply_punc = True
                    
                    if should_apply_punc and self.pending_text:
                        # ä½¿ç”¨å®æ—¶æ ‡ç‚¹æ¨¡å‹
                        punc_text = self._apply_realtime_punc(self.pending_text)
                        self.text_with_punc += punc_text
                        
                        # è®°å½•å¸¦æ—¶é—´æˆ³çš„ç‰‡æ®µï¼ˆå®æ—¶ç²—ç•¥æ—¶é—´æˆ³ï¼‰
                        current_segment = {
                            'text': punc_text,
                            'start_ms': self.current_segment_start,
                            'end_ms': chunk_end_ms
                        }
                        self.segments.append(current_segment)
                        
                        # æ›´æ–°ä¸‹ä¸€ä¸ªç‰‡æ®µçš„èµ·å§‹æ—¶é—´
                        self.current_segment_start = chunk_end_ms
                        self.pending_text = ""
                        
                        # å¦‚æœæ˜¯ VAD ç»“æŸäº‹ä»¶ï¼Œé‡ç½®å¥å­ç¼“å†²åŒº
                        if vad_event and vad_event.get('type') == 'end':
                            self.sentence_buffer = ""
            
            return {
                "text": text,
                "punc_text": punc_text,
                "full_text": self.text_with_punc + self.pending_text,
                "is_final": False,
                "vad_event": vad_event,
                "is_speech_active": self.is_speech_active,
                "segment": current_segment,  # å½“å‰ç‰‡æ®µçš„æ—¶é—´æˆ³ä¿¡æ¯
                "current_time_ms": chunk_end_ms  # å½“å‰éŸ³é¢‘æ—¶é—´
            }
            
        except Exception as e:
            print(f"âŒ æµå¼è¯†åˆ«é”™è¯¯: {str(e)}")
            return None
    
    def finalize(self):
        """å®Œæˆè¯†åˆ«ï¼Œç”Ÿæˆæœ€ç»ˆç»“æœ"""
        try:
            # å¤„ç†æœ€åå‰©ä½™çš„éŸ³é¢‘
            if len(self.audio_buffer) >= 4800:  # è‡³å°‘ 300ms
                speech_chunk = np.array(self.audio_buffer, dtype=np.float32)
                asr_result = asr_model.generate(
                    input=speech_chunk,
                    cache=self.asr_cache,
                    is_final=True,
                    chunk_size=self.chunk_size,
                )
                
                if asr_result and len(asr_result) > 0:
                    text = asr_result[0].get("text", "")
                    if text:
                        self.all_text += text
                        self.pending_text += text
            
            # å¯¹å‰©ä½™å¾…å¤„ç†æ–‡æœ¬ä½¿ç”¨ç¦»çº¿æ ‡ç‚¹æ¨¡å‹ï¼ˆæ›´å‡†ç¡®ï¼‰
            if self.pending_text and punc_model:
                try:
                    punc_result = punc_model.generate(input=self.pending_text)
                    if punc_result and len(punc_result) > 0:
                        self.text_with_punc += punc_result[0].get("text", self.pending_text)
                except Exception as e:
                    print(f"âš ï¸ æœ€ç»ˆæ ‡ç‚¹æ¢å¤å¤±è´¥: {str(e)}")
                    self.text_with_punc += self.pending_text
            else:
                self.text_with_punc += self.pending_text
            
            paraformer_text = self.text_with_punc
            print(f"âœ… Paraformerå®Œæ•´æ–‡æœ¬: {paraformer_text} ({len(paraformer_text)}å­—)")
            
            # ä½¿ç”¨ SenseVoice å¯¹å®Œæ•´éŸ³é¢‘è¿›è¡Œè¯†åˆ«
            sensevoice_text = ""
            if len(self.full_audio) > 0:
                print(f"ğŸ” å¼€å§‹SenseVoiceå®Œæ•´è¯†åˆ«...")
                try:
                    audio_array = np.array(self.full_audio, dtype=np.float32)
                    sensevoice_text = _run_sensevoice_array(audio_array, self.sample_rate)
                    print(f"âœ… SenseVoiceå®Œæ•´æ–‡æœ¬: {sensevoice_text} ({len(sensevoice_text)}å­—)")
                except Exception as e:
                    print(f"âŒ SenseVoiceå®Œæ•´è¯†åˆ«å¤±è´¥: {str(e)}")
            
            # è°ƒç”¨ LLM åˆå¹¶çº é”™
            llm_merged_text = ""
            if paraformer_text or sensevoice_text:
                llm_merged_text = _call_llm_merge(paraformer_text, sensevoice_text)
                print(f"âœ… LLMåˆå¹¶æ–‡æœ¬: {llm_merged_text} ({len(llm_merged_text)}å­—)")
            
            # ä½¿ç”¨ fa-zh æ¨¡å‹ä¸º LLM çº é”™åçš„æ–‡æœ¬ç”Ÿæˆç²¾ç¡®å­—çº§æ—¶é—´æˆ³
            timestamps = []
            final_text = llm_merged_text or sensevoice_text or paraformer_text
            if final_text and len(self.full_audio) > 0 and timestamp_model:
                print(f"ğŸ• å¼€å§‹ç”Ÿæˆç²¾ç¡®æ—¶é—´æˆ³...")
                try:
                    timestamps = _generate_timestamps(
                        np.array(self.full_audio, dtype=np.float32),
                        self.sample_rate,
                        final_text
                    )
                    print(f"âœ… æ—¶é—´æˆ³ç”Ÿæˆå®Œæˆ: {len(timestamps)} ä¸ªç‰‡æ®µ")
                except Exception as e:
                    print(f"âš ï¸ æ—¶é—´æˆ³ç”Ÿæˆå¤±è´¥: {str(e)}")
                    # å¦‚æœç²¾ç¡®æ—¶é—´æˆ³å¤±è´¥ï¼Œä½¿ç”¨å®æ—¶æ—¶é—´æˆ³ä½œä¸ºå¤‡é€‰
                    timestamps = self.segments
            
            return {
                'paraformer': paraformer_text,
                'sensevoice': sensevoice_text,
                'llm_merged': llm_merged_text,
                'paraformer_length': len(paraformer_text),
                'sensevoice_length': len(sensevoice_text),
                'llm_merged_length': len(llm_merged_text),
                'timestamps': timestamps,  # ç²¾ç¡®å­—çº§æ—¶é—´æˆ³
                'realtime_segments': self.segments,  # å®æ—¶ç²—ç•¥æ—¶é—´æˆ³ï¼ˆå¤‡ç”¨ï¼‰
            }
            
        except Exception as e:
            print(f"âŒ æœ€ç»ˆè¯†åˆ«é”™è¯¯: {str(e)}")
            return {
                'paraformer': self.text_with_punc + self.pending_text,
                'sensevoice': '',
                'llm_merged': '',
                'paraformer_length': len(self.text_with_punc + self.pending_text),
                'sensevoice_length': 0,
                'llm_merged_length': 0,
            }


# ==================== WebSocket äº‹ä»¶å¤„ç† ====================

@socketio.on('connect')
def handle_connect():
    """å®¢æˆ·ç«¯è¿æ¥"""
    session_id = request.sid
    print(f"âœ… å®¢æˆ·ç«¯è¿æ¥: {session_id}")
    emit('connected', {'session_id': session_id})


@socketio.on('disconnect')
def handle_disconnect():
    """å®¢æˆ·ç«¯æ–­å¼€"""
    session_id = request.sid
    if session_id in active_sessions:
        del active_sessions[session_id]
    print(f"âŒ å®¢æˆ·ç«¯æ–­å¼€: {session_id}")


@socketio.on('start_recording')
def handle_start_recording():
    """å¼€å§‹å½•éŸ³"""
    session_id = request.sid
    active_sessions[session_id] = RealtimeASR(session_id)
    print(f"ğŸ™ï¸ å¼€å§‹å½•éŸ³: {session_id}")
    emit('recording_started', {'status': 'ok'})


@socketio.on('audio_data')
def handle_audio_data(data):
    """æ¥æ”¶éŸ³é¢‘æ•°æ®"""
    session_id = request.sid
    
    if session_id not in active_sessions:
        emit('error', {'message': 'ä¼šè¯ä¸å­˜åœ¨'})
        return
    
    try:
        asr = active_sessions[session_id]
        asr.add_audio(data)
        
        # å¤„ç†éŸ³é¢‘å¹¶è¿”å›å®æ—¶ç»“æœ
        result = asr.process_audio()
        if result:
            emit('transcription', result)
    except Exception as e:
        print(f"âŒ éŸ³é¢‘å¤„ç†é”™è¯¯ [{session_id}]: {str(e)}")
        # ä¸å‘é€é”™è¯¯ï¼Œé¿å…ä¸­æ–­å½•éŸ³æµç¨‹


@socketio.on('stop_recording')
def handle_stop_recording():
    """åœæ­¢å½•éŸ³"""
    session_id = request.sid
    
    if session_id not in active_sessions:
        emit('error', {'message': 'ä¼šè¯ä¸å­˜åœ¨'})
        return
    
    print(f"ğŸ›‘ åœæ­¢å½•éŸ³: {session_id}")
    asr = active_sessions[session_id]
    
    # é€šçŸ¥å‰ç«¯å½•éŸ³å·²åœæ­¢ï¼Œå¼€å§‹LLMå¤„ç†
    emit('recording_stopped', {'message': 'å½•éŸ³å·²åœæ­¢ï¼Œå¼€å§‹LLMçº é”™'})
    
    try:
        # ç”Ÿæˆæœ€ç»ˆç»“æœï¼ˆå¯èƒ½è€—æ—¶è¾ƒé•¿ï¼ŒåŒ…å«SenseVoiceå’ŒLLMå¤„ç†ï¼‰
        final_result = asr.finalize()
        emit('final_result', final_result)
    except Exception as e:
        print(f"âŒ æœ€ç»ˆå¤„ç†é”™è¯¯ [{session_id}]: {str(e)}")
        traceback.print_exc()
        # è¿”å›å·²æœ‰çš„éƒ¨åˆ†ç»“æœ
        emit('final_result', {
            'paraformer': asr.text_with_punc + asr.pending_text,
            'sensevoice': '',
            'llm_merged': '',
            'paraformer_length': len(asr.text_with_punc + asr.pending_text),
            'sensevoice_length': 0,
            'llm_merged_length': 0,
            'error': str(e)
        })
    finally:
        # ç¡®ä¿æ¸…ç†ä¼šè¯
        if session_id in active_sessions:
            del active_sessions[session_id]


# ==================== REST API è·¯ç”± ====================

@app.route('/api/health', methods=['GET'])
def health_check():
    """
    å¥åº·æ£€æŸ¥æ¥å£
    """
    return jsonify({
        "status": "ok",
        "message": "ASR APIæœåŠ¡æ­£å¸¸è¿è¡Œ",
        "models_loaded": asr_model is not None
    }), 200


@app.route('/api/asr/transcribe', methods=['POST'])
def transcribe_audio():
    """
    éŸ³é¢‘æ–‡ä»¶è½¬å½•æ¥å£
    ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼Œä»…ä½¿ç”¨SenseVoiceè¿›è¡Œè¯†åˆ«ï¼ˆé«˜å‡†ç¡®åº¦ï¼‰
    ä¸ä½¿ç”¨Paraformerå’ŒLLMï¼Œç›´æ¥è¿”å›SenseVoiceç»“æœ
    """
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶
        if 'file' not in request.files:
            return jsonify({
                "success": False,
                "error": "æœªæ‰¾åˆ°ä¸Šä¼ çš„æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ 'file' å­—æ®µä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"
            }), 400
        
        file = request.files['file']
        
        # æ£€æŸ¥æ–‡ä»¶å
        if file.filename == '':
            return jsonify({
                "success": False,
                "error": "æ–‡ä»¶åä¸ºç©º"
            }), 400
        
        # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
        if not allowed_file(file.filename):
            return jsonify({
                "success": False,
                "error": f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œæ”¯æŒçš„æ ¼å¼: {', '.join(ALLOWED_EXTENSIONS)}"
            }), 400
        
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ä½ç½®
        temp_upload = tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.filename)[1])
        temp_upload_path = temp_upload.name
        file.save(temp_upload_path)
        temp_upload.close()
        
        # å°†éŸ³é¢‘è½¬æ¢ä¸ºWAVæ ¼å¼ï¼ˆç¡®ä¿æ‰€æœ‰æ ¼å¼éƒ½èƒ½è¢«æ­£ç¡®å¤„ç†ï¼‰
        temp_wav = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
        temp_path = temp_wav.name
        temp_wav.close()
        
        try:
            print(f"ğŸ“ å¼€å§‹å¤„ç†æ–‡ä»¶: {file.filename}")
            
            # ä½¿ç”¨librosaè¯»å–å¹¶è½¬æ¢ä¸ºWAVæ ¼å¼
            print("ğŸ”„ è½¬æ¢éŸ³é¢‘æ ¼å¼...")
            audio_data, sr = librosa.load(temp_upload_path, sr=16000, mono=True)
            sf.write(temp_path, audio_data, sr)
            print(f"âœ… æ ¼å¼è½¬æ¢å®Œæˆ: 16kHz, å•å£°é“")
            
            # åˆ é™¤ä¸Šä¼ çš„ä¸´æ—¶æ–‡ä»¶
            os.remove(temp_upload_path)
            
            # ä»…ä½¿ç”¨SenseVoiceè¯†åˆ«ï¼ˆæ–‡ä»¶ä¸Šä¼ æ¨¡å¼ï¼‰
            print("âœ¨ SenseVoiceè¯†åˆ«ä¸­...")
            sensevoice_text = _run_sensevoice(temp_path)
            print(f"âœ… SenseVoiceå®Œæˆ: {len(sensevoice_text)}å­—")
            
            # è¿”å›ç»“æœï¼ˆä»…SenseVoiceç»“æœï¼‰
            return jsonify({
                "success": True,
                "data": {
                    "text": sensevoice_text,
                    "length": len(sensevoice_text),
                    "model": "SenseVoice"
                },
                "filename": file.filename,
                "mode": "file_upload"
            }), 200
            
        finally:
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_path):
                os.remove(temp_path)
        
    except Exception as e:
        print(f"âŒ å¤„ç†é”™è¯¯: {str(e)}")
        traceback.print_exc()
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


@app.route('/api/asr/models', methods=['GET'])
def get_models_info():
    """
    è·å–æ¨¡å‹ä¿¡æ¯
    """
    return jsonify({
        "success": True,
        "data": {
            "asr_model": "paraformer-zh-streaming",
            "punc_model": "ct-punc",
            "sensevoice_model": "iic/SenseVoiceSmall",
            "llm_model": LLM_MODEL,
            "models_loaded": asr_model is not None
        }
    }), 200


@app.route('/api/asr/formats', methods=['GET'])
def get_supported_formats():
    """
    è·å–æ”¯æŒçš„éŸ³é¢‘æ ¼å¼
    """
    return jsonify({
        "success": True,
        "data": {
            "formats": list(ALLOWED_EXTENSIONS),
            "description": "æ”¯æŒçš„éŸ³é¢‘æ–‡ä»¶æ ¼å¼"
        }
    }), 200


@app.route('/api/asr/hotwords', methods=['GET'])
def get_hotwords():
    """
    è·å–å½“å‰åŠ è½½çš„çƒ­è¯åˆ—è¡¨
    """
    return jsonify({
        "success": True,
        "data": {
            "hotwords": hotwords_cache,
            "count": len(hotwords_cache),
            "file_path": HOTWORDS_FILE
        }
    }), 200


@app.route('/api/asr/hotwords/reload', methods=['POST'])
def reload_hotwords_api():
    """
    é‡æ–°åŠ è½½çƒ­è¯é…ç½®ï¼ˆæ— éœ€é‡å¯æœåŠ¡å™¨ï¼‰
    """
    try:
        hotwords = reload_hotwords()
        return jsonify({
            "success": True,
            "message": "çƒ­è¯é‡æ–°åŠ è½½æˆåŠŸ",
            "data": {
                "hotwords": hotwords,
                "count": len(hotwords)
            }
        }), 200
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


if __name__ == '__main__':
    print("=" * 60)
    print("ğŸ“£ è¯­éŸ³è¯†åˆ«APIæœåŠ¡å™¨")
    print("=" * 60)
    print("ğŸ“ æ”¯æŒæ¨¡å¼:")
    print("  1. å®æ—¶å½•éŸ³æ¨¡å¼ï¼ˆWebSocketï¼‰:")
    print("     - Paraformer å®æ—¶æµå¼è¯†åˆ«")
    print("     - SenseVoice å®Œæ•´éŸ³é¢‘è¯†åˆ«")
    print("     - LLM æ™ºèƒ½åˆå¹¶çº é”™")
    print("  2. æ–‡ä»¶ä¸Šä¼ æ¨¡å¼ï¼ˆREST APIï¼‰:")
    print("     - ä»… SenseVoice è¯†åˆ«ï¼ˆé«˜å‡†ç¡®åº¦ï¼‰")
    print("=" * 60)
    print("ğŸ”§ REST APIæ¥å£:")
    print("  - GET  /api/health              å¥åº·æ£€æŸ¥")
    print("  - POST /api/asr/transcribe      æ–‡ä»¶è½¬å½•ï¼ˆä»…SenseVoiceï¼‰")
    print("  - GET  /api/asr/models          æ¨¡å‹ä¿¡æ¯")
    print("  - GET  /api/asr/formats         æ”¯æŒæ ¼å¼")
    print("  - GET  /api/asr/hotwords        è·å–çƒ­è¯åˆ—è¡¨")
    print("  - POST /api/asr/hotwords/reload é‡æ–°åŠ è½½çƒ­è¯")
    print("")
    print("ğŸ”Œ WebSocketæ¥å£:")
    print("  - connect                    å»ºç«‹è¿æ¥")
    print("  - start_recording            å¼€å§‹å½•éŸ³")
    print("  - audio_data                 å‘é€éŸ³é¢‘æ•°æ®")
    print("  - stop_recording             åœæ­¢å½•éŸ³")
    print("  - transcription              æ¥æ”¶å®æ—¶è¯†åˆ«")
    print("  - recording_stopped          å½•éŸ³å·²åœæ­¢ï¼Œå¼€å§‹LLMå¤„ç†")
    print("  - final_result               æ¥æ”¶æœ€ç»ˆç»“æœ")
    print("=" * 60)
    print("ğŸŒ è®¿é—®åœ°å€: http://localhost:5006")
    print("=" * 60)
    
    # åˆå§‹åŒ–æ¨¡å‹
    init_models()
    
    # åŠ è½½çƒ­è¯
    load_hotwords()
    
    # å¯åŠ¨æœåŠ¡ï¼ˆä½¿ç”¨socketio.runæ”¯æŒWebSocketï¼‰
    socketio.run(app, host='0.0.0.0', port=5006, debug=False, allow_unsafe_werkzeug=True)

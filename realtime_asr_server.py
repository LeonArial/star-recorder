"""
å®æ—¶è¯­éŸ³è¯†åˆ«æœåŠ¡å™¨
æ”¯æŒ WebSocket å®æ—¶ä¼ è¾“éŸ³é¢‘æ•°æ®å¹¶è¿”å›è¯†åˆ«ç»“æœ
"""
import asyncio
import json
import os
import tempfile
import wave
import numpy as np
from flask import Flask, render_template, request
from flask_socketio import SocketIO, emit
from funasr import AutoModel
import threading
import queue
import time

app = Flask(__name__)
app.config['SECRET_KEY'] = 'sensevoice-realtime-asr'
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

# å…¨å±€æ¨¡å‹å®ä¾‹
asr_model = None
vad_model = None
punc_model = None
sensevoice_model = None

# SenseVoice å¤æ£€ç›¸å…³
sensevoice_queue = queue.Queue()
sensevoice_worker_started = False

# æ¨¡å‹åŠ è½½é”
model_lock = threading.Lock()

def init_models():
    """åˆå§‹åŒ– ASRã€VADã€æ ‡ç‚¹ä¸å¤æ£€æ¨¡å‹"""
    global asr_model, vad_model, punc_model, sensevoice_model
    
    with model_lock:
        if asr_model is None:
            print("ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹...")
            
            # åŠ è½½ä¸­æ–‡æµå¼ ASR æ¨¡å‹
            print("  - åŠ è½½ ASR æ¨¡å‹: paraformer-zh-streaming")
            asr_model = AutoModel(
                model="paraformer-zh-streaming",
                device="cuda:0",  # æ”¹ä¸º "cuda:0" ä½¿ç”¨ GPU
                disable_update=True,
            )
            
            # åŠ è½½ VAD æ¨¡å‹ï¼ˆè¯­éŸ³ç«¯ç‚¹æ£€æµ‹ï¼‰
            print("  - åŠ è½½ VAD æ¨¡å‹: fsmn-vad")
            vad_model = AutoModel(
                model="fsmn-vad",
                device="cuda:0",
                disable_update=True,
            )
            
            # åŠ è½½æ ‡ç‚¹æ¢å¤æ¨¡å‹
            print("  - åŠ è½½æ ‡ç‚¹æ¨¡å‹: ct-punc")
            punc_model = AutoModel(
                model="ct-punc",
                device="cuda:0",
                disable_update=True,
            )
            
            # SenseVoice å¤æ£€æ¨¡å‹
            print("  - åŠ è½½å¤æ£€æ¨¡å‹: SenseVoiceSmall")
            sensevoice_model = AutoModel(
                model="iic/SenseVoiceSmall",
                trust_remote_code=True,
                device="cuda:0",
                disable_update=True,
            )
            
            print("âœ… æ‰€æœ‰æ¨¡å‹åŠ è½½å®Œæˆï¼")
            _start_sensevoice_worker()


def _start_sensevoice_worker():
    """å¯åŠ¨åå° SenseVoice å¤æ£€çº¿ç¨‹"""
    global sensevoice_worker_started
    if sensevoice_worker_started:
        return

    worker = threading.Thread(target=_sensevoice_worker_loop, daemon=True)
    worker.start()
    sensevoice_worker_started = True


def _sensevoice_worker_loop():
    while True:
        task = sensevoice_queue.get()
        if task is None:
            break

        if sensevoice_model is None:
            sensevoice_queue.task_done()
            continue

        try:
            review_text = _run_sensevoice(task["audio"], task["sample_rate"])
            payload = {
                "segment_id": task["segment_id"],
                "text": review_text,
                "preview_text": task.get("preview_text", ""),
            }
            socketio.emit('sensevoice_review', payload, to=task["session_id"])
            print(f"ğŸ” SenseVoice å¤æ£€å®Œæˆ: session={task['session_id']} segment={task['segment_id']}")
        except Exception as exc:
            print(f"âŒ SenseVoice å¤æ£€å¤±è´¥: {exc}")
        finally:
            sensevoice_queue.task_done()


def _run_sensevoice(audio_samples, sample_rate):
    """è°ƒç”¨ SenseVoiceSmall å¯¹éŸ³é¢‘æ®µè¿›è¡Œå¤æ£€"""
    if audio_samples.size == 0:
        return ""

    temp_path = None
    try:
        temp_path = _save_temp_wav(audio_samples, sample_rate)
        result = sensevoice_model.generate(
            input=temp_path,
            cache={},
            language="auto",
            use_itn=True,
            merge_vad=True,
        )
        if result and len(result) > 0:
            return result[0].get("text", "")
        return ""
    finally:
        if temp_path and os.path.exists(temp_path):
            os.remove(temp_path)


def _save_temp_wav(samples, sample_rate):
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    tmp.close()
    audio_int16 = np.clip(samples, -1, 1)
    audio_int16 = (audio_int16 * 32767).astype(np.int16)
    with wave.open(tmp.name, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)
        wf.setframerate(sample_rate)
        wf.writeframes(audio_int16.tobytes())
    return tmp.name


def enqueue_sensevoice_task(session_id, segment_id, audio_samples, preview_text, sample_rate=16000):
    """æ”¾å…¥ SenseVoice å¤æ£€ä»»åŠ¡é˜Ÿåˆ—"""
    if sensevoice_model is None or audio_samples.size == 0:
        return
    task = {
        "session_id": session_id,
        "segment_id": segment_id,
        "audio": audio_samples,
        "preview_text": preview_text,
        "sample_rate": sample_rate,
    }
    sensevoice_queue.put(task)

class RealtimeASR:
    """å®æ—¶è¯­éŸ³è¯†åˆ«å¤„ç†å™¨"""
    
    def __init__(self, session_id):
        self.session_id = session_id
        self.audio_buffer = []
        self.sample_rate = 16000
        self.is_processing = False
        self.last_result = ""
        self.cache = {}  # æµå¼è¯†åˆ«ç¼“å­˜
        self.chunk_size = [0, 10, 5]  # [0, 10, 5] è¡¨ç¤º600mså®æ—¶å‡ºå­—ï¼Œ300msæœªæ¥ä¿¡æ¯
        self.chunk_stride = self.chunk_size[1] * 960  # 600mså¯¹åº”çš„é‡‡æ ·ç‚¹æ•°
        self.all_text = ""  # ç´¯ç§¯æ‰€æœ‰è¯†åˆ«æ–‡æœ¬ï¼ˆæ— æ ‡ç‚¹ï¼‰
        self.text_with_punc = ""  # å·²æ·»åŠ æ ‡ç‚¹çš„æ–‡æœ¬
        self.pending_text = ""  # ç­‰å¾…æ ‡ç‚¹çš„æ–‡æœ¬
        self.punc_threshold = 30  # ç´¯ç§¯åˆ°30å­—ç¬¦æ—¶åšæ ‡ç‚¹
        self.segment_audio = []  # å•æ®µéŸ³é¢‘ç¼“å­˜
        self.segment_id = 0
        
    def add_audio(self, audio_data):
        """æ·»åŠ éŸ³é¢‘æ•°æ®åˆ°ç¼“å†²åŒº"""
        try:
            # ç¡®ä¿æ•°æ®é•¿åº¦æ˜¯ 2 çš„å€æ•°ï¼ˆint16 = 2 bytesï¼‰
            if len(audio_data) % 2 != 0:
                # å¦‚æœä¸æ˜¯å¶æ•°ï¼Œæˆªæ–­æœ€åä¸€ä¸ªå­—èŠ‚
                audio_data = audio_data[:-1]
            
            if len(audio_data) == 0:
                return
            
            # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸º float32 numpy æ•°ç»„
            audio_np = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0
            self.audio_buffer.extend(audio_np)
            self.segment_audio.extend(audio_np)
        except Exception as e:
            print(f"âŒ éŸ³é¢‘æ•°æ®å¤„ç†é”™è¯¯: {e}, æ•°æ®é•¿åº¦: {len(audio_data)}")
        
    def process_audio(self):
        """å¤„ç†ç¼“å†²åŒºä¸­çš„éŸ³é¢‘ï¼ˆæµå¼ï¼‰"""
        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„éŸ³é¢‘æ•°æ®ï¼ˆ600msï¼‰
        if len(self.audio_buffer) < self.chunk_stride:
            return None
        
        try:
            # å–å‡ºä¸€ä¸ª chunk çš„éŸ³é¢‘
            speech_chunk = np.array(self.audio_buffer[:self.chunk_stride], dtype=np.float32)
            
            # æµå¼ ASR è¯†åˆ«
            asr_result = asr_model.generate(
                input=speech_chunk,
                cache=self.cache,
                is_final=False,
                chunk_size=self.chunk_size,
                encoder_chunk_look_back=4,
                decoder_chunk_look_back=1,
            )
            
            if asr_result and len(asr_result) > 0:
                text = asr_result[0]["text"]
                
                # ç´¯ç§¯åŸå§‹æ–‡æœ¬
                self.all_text += text
                self.pending_text += text
                
                # ç§»é™¤å·²å¤„ç†çš„éŸ³é¢‘
                self.audio_buffer = self.audio_buffer[self.chunk_stride:]
                
                # å¢é‡æ ‡ç‚¹æ¢å¤ï¼ˆç´¯ç§¯åˆ°é˜ˆå€¼æ—¶å¤„ç†ï¼‰
                punc_text = ""
                if len(self.pending_text) >= self.punc_threshold and punc_model:
                    try:
                        # å¯¹å¾…å¤„ç†æ–‡æœ¬åšæ ‡ç‚¹
                        punc_result = punc_model.generate(input=self.pending_text)
                        if punc_result and len(punc_result) > 0:
                            punc_text = punc_result[0]["text"]
                            
                            # ä¿ç•™æœ€å10ä¸ªå­—ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œé¿å…æ–­å¥ä¸è¿è´¯
                            if len(self.pending_text) > 10:
                                # å·²ç¡®è®¤çš„å¸¦æ ‡ç‚¹æ–‡æœ¬
                                confirmed = punc_text[:-10] if len(punc_text) > 10 else ""
                                self.text_with_punc += confirmed
                                
                                # å‰©ä½™éƒ¨åˆ†ç»§ç»­ç­‰å¾…
                                self.pending_text = self.pending_text[-10:]
                            else:
                                self.text_with_punc += punc_text
                                self.pending_text = ""
                    except Exception as e:
                        print(f"âš ï¸ å¢é‡æ ‡ç‚¹å¤±è´¥: {e}")
                
                # è¿”å›å¢é‡ç»“æœ
                return {
                    "text": text,  # åŸå§‹æ–°å¢æ–‡æœ¬
                    "full_text_with_punc": self.text_with_punc + self.pending_text,  # å®Œæ•´å¸¦æ ‡ç‚¹æ–‡æœ¬
                    "is_final": False,
                }
            else:
                self._maybe_commit_segment(text)
        except Exception as e:
            print(f"âŒ è¯†åˆ«é”™è¯¯: {e}")
        except Exception as e:
            print(f"âŒ è¯†åˆ«é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            
        return None
    
    def finalize(self):
        """å¤„ç†å‰©ä½™çš„éŸ³é¢‘å¹¶è¿”å›æœ€ç»ˆç»“æœ"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å‰©ä½™éŸ³é¢‘æˆ–ç¼“å­˜å†…å®¹
            if len(self.audio_buffer) > 0:
                # æœ‰å‰©ä½™éŸ³é¢‘ï¼šå¤„ç†å‰©ä½™éŸ³é¢‘
                speech_chunk = np.array(self.audio_buffer, dtype=np.float32)
                
                # æœ€åä¸€ä¸ªchunkï¼Œè®¾ç½® is_final=True å¼ºåˆ¶è¾“å‡ºç¼“å­˜
                asr_result = asr_model.generate(
                    input=speech_chunk,
                    cache=self.cache,
                    is_final=True,  # å¼ºåˆ¶è¾“å‡ºæœ€åä¸€ä¸ªå­—
                    chunk_size=self.chunk_size,
                    encoder_chunk_look_back=4,
                    decoder_chunk_look_back=1,
                )
            elif self.cache:
                # æ²¡æœ‰å‰©ä½™éŸ³é¢‘ä½†æœ‰ç¼“å­˜ï¼šå‘é€ä¸€ä¸ªå®Œæ•´çš„é™éŸ³chunk
                speech_chunk = np.zeros(self.chunk_stride, dtype=np.float32)  # 600ms é™éŸ³
                
                asr_result = asr_model.generate(
                    input=speech_chunk,
                    cache=self.cache,
                    is_final=True,
                    chunk_size=self.chunk_size,
                    encoder_chunk_look_back=4,
                    decoder_chunk_look_back=1,
                )
            else:
                # æ—¢æ²¡æœ‰å‰©ä½™éŸ³é¢‘ä¹Ÿæ²¡æœ‰ç¼“å­˜ï¼šç›´æ¥è¿”å›å·²æœ‰æ–‡æœ¬
                asr_result = None
            
            if asr_result and len(asr_result) > 0:
                text = asr_result[0]["text"]
                if text:  # åªæœ‰éç©ºæ–‡æœ¬æ‰ç´¯ç§¯
                    self.all_text += text
                    self.pending_text += text
                    print(f"ğŸ“ æœ€ç»ˆè¯†åˆ«: {text}")
            
            # å¯¹å‰©ä½™å¾…å¤„ç†æ–‡æœ¬è¿›è¡Œæœ€ç»ˆæ ‡ç‚¹æ¢å¤
            if self.pending_text and punc_model:
                try:
                    punc_result = punc_model.generate(input=self.pending_text)
                    if punc_result and len(punc_result) > 0:
                        self.text_with_punc += punc_result[0]["text"]
                except Exception as e:
                    print(f"âš ï¸ æœ€ç»ˆæ ‡ç‚¹æ¢å¤å¤±è´¥: {e}")
                    self.text_with_punc += self.pending_text
            else:
                self.text_with_punc += self.pending_text
            
            final_text = self.text_with_punc
            
            print(f"âœ… å®Œæ•´æ–‡æœ¬: {final_text}")
            print(f"ğŸ“Š æ€»å­—æ•°: {len(final_text)}")
            
            # æ¸…ç©ºæ‰€æœ‰çŠ¶æ€
            self.audio_buffer = []
            self.cache = {}
            self.all_text = ""
            self.text_with_punc = ""
            self.pending_text = ""
            self._commit_segment(force=True, final_text=final_text)
            
            return {
                "text": final_text,
                "full_text_with_punc": final_text,
                "is_final": True,
            }
        except Exception as e:
            print(f"âŒ æœ€ç»ˆè¯†åˆ«é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            
            # å³ä½¿å‡ºé”™ï¼Œä¹Ÿè¿”å›å·²æœ‰çš„æ–‡æœ¬
            return {
                "text": self.text_with_punc + self.pending_text,
                "full_text_with_punc": self.text_with_punc + self.pending_text,
                "is_final": True,
            }

    def _maybe_commit_segment(self, latest_text):
        """æ ¹æ®æ ‡ç‚¹æˆ–é•¿åº¦è§¦å‘å¤æ£€æ®µæäº¤"""
        if not self.segment_audio:
            return
        punctuation_trigger = any(p in latest_text for p in "ã€‚ï¼Ÿï¼!?")
        duration_trigger = len(self.segment_audio) >= self.sample_rate * 10
        if punctuation_trigger or duration_trigger:
            self._commit_segment()

    def _commit_segment(self, force=False, final_text=""):
        if not self.segment_audio:
            return
        if not force and len(self.segment_audio) < self.sample_rate:  # å°‘äº1ç§’ä¸é€æ£€
            return
        segment_samples = np.array(self.segment_audio, dtype=np.float32)
        self.segment_audio = []
        segment_id = self.segment_id
        self.segment_id += 1
        preview_text = final_text or (self.text_with_punc + self.pending_text)
        enqueue_sensevoice_task(
            session_id=self.session_id,
            segment_id=segment_id,
            audio_samples=segment_samples,
            preview_text=preview_text,
            sample_rate=self.sample_rate,
        )

# å­˜å‚¨æ‰€æœ‰ä¼šè¯
sessions = {}

@app.route('/')
def index():
    """ä¸»é¡µ"""
    return render_template('realtime_asr.html')

@socketio.on('connect')
def handle_connect():
    """å®¢æˆ·ç«¯è¿æ¥"""
    sid = request.sid
    print(f"âœ… å®¢æˆ·ç«¯è¿æ¥: {sid}")
    
    # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
    if asr_model is None:
        init_models()
    
    # åˆ›å»ºæ–°ä¼šè¯
    sessions[sid] = RealtimeASR(sid)
    emit('connected', {'status': 'ready'})

@socketio.on('disconnect')
def handle_disconnect():
    """å®¢æˆ·ç«¯æ–­å¼€"""
    sid = request.sid
    print(f"âŒ å®¢æˆ·ç«¯æ–­å¼€: {sid}")
    if sid in sessions:
        del sessions[sid]

@socketio.on('start_recording')
def handle_start_recording():
    """å¼€å§‹å½•éŸ³"""
    sid = request.sid
    print(f"ğŸ™ï¸ å¼€å§‹å½•éŸ³: {sid}")
    if sid in sessions:
        sessions[sid].audio_buffer = []
        sessions[sid].cache = {}
        sessions[sid].all_text = ""
        sessions[sid].text_with_punc = ""
        sessions[sid].pending_text = ""
        emit('recording_started', {'status': 'recording'})

@socketio.on('audio_data')
def handle_audio_data(data):
    """æ¥æ”¶éŸ³é¢‘æ•°æ®"""
    sid = request.sid
    if sid not in sessions:
        return
    
    session = sessions[sid]
    
    # æ·»åŠ éŸ³é¢‘æ•°æ®
    audio_bytes = data.get('audio')
    if audio_bytes:
        session.add_audio(audio_bytes)
        
        # å¤„ç†éŸ³é¢‘å¹¶è¿”å›ç»“æœ
        result = session.process_audio()
        if result:
            emit('transcription', result)

@socketio.on('stop_recording')
def handle_stop_recording():
    """åœæ­¢å½•éŸ³"""
    sid = request.sid
    print(f"â¹ï¸ åœæ­¢å½•éŸ³: {sid}")
    if sid not in sessions:
        return
    
    session = sessions[sid]
    
    # å¤„ç†å‰©ä½™éŸ³é¢‘
    result = session.finalize()
    if result:
        emit('transcription', result)
    
    emit('recording_stopped', {'status': 'stopped'})

if __name__ == '__main__':
    print("=" * 60)
    print("ğŸ™ï¸ å®æ—¶ä¸­æ–‡è¯­éŸ³è¯†åˆ«æœåŠ¡å™¨")
    print("=" * 60)
    print("ğŸ“ åŠŸèƒ½:")
    print("  - å®æ—¶æµå¼è¯­éŸ³è¯†åˆ« (600mså»¶è¿Ÿ)")
    print("  - è¯­éŸ³ç«¯ç‚¹æ£€æµ‹ (VAD)")
    print("  - è‡ªåŠ¨æ ‡ç‚¹æ¢å¤")
    print("  - ä¸­æ–‡ä¸“ç”¨ä¼˜åŒ–")
    print("=" * 60)
    print("ğŸ”§ æ¨¡å‹:")
    print("  - ASR: paraformer-zh-streaming")
    print("  - VAD: fsmn-vad")
    print("  - æ ‡ç‚¹: ct-punc")
    print("=" * 60)
    print("ğŸŒ è®¿é—®åœ°å€: http://localhost:5005")
    print("=" * 60)
    
    # é¢„åŠ è½½æ¨¡å‹
    init_models()
    
    # å¯åŠ¨æœåŠ¡å™¨
    socketio.run(app, host='0.0.0.0', port=5005, debug=False)
